{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c28ce7c2",
   "metadata": {},
   "source": [
    "# Debug\n",
    "\n",
    "Debugging on machine learning project can be very difficult. In this project, subject model and object model are rather seperated, the debug task can be divided into debugging `SubjectModel` and debugging `ObjectModel`.\n",
    "\n",
    "Some resources on dubugging ML projects:\n",
    "[How to unit test machine learning code](https://thenerdstation.medium.com/how-to-unit-test-machine-learning-code-57cf6fd81765)\n",
    "[What should I do when my neural network doesn't learn?](https://stats.stackexchange.com/questions/352036/what-should-i-do-when-my-neural-network-doesnt-learn)\n",
    "\n",
    "## Preparation (load data etc.)\n",
    "\n",
    "First we import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d902255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.auto import trange\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from data_gen import BertDataGenerator, DevDataGenerator, MyDataset, MyDevDataset, collate_fn, dev_collate_fn\n",
    "from model_bert_based import SubjectModel, ObjectModel\n",
    "from utils import para_eval\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6662e65",
   "metadata": {},
   "source": [
    "Load training and dev data and define constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL_NAME = config.bert_model_name\n",
    "LEARNING_RATE = config.learning_rate\n",
    "WORD_EMB_SIZE = config.word_emb_size # default bert embedding size\n",
    "EPOCH_NUM = config.epoch_num\n",
    "BATCH_SIZE = config.batch_size\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "file_dir = os.getcwd()\n",
    "train_path = os.path.join(file_dir, 'generated/train_data_me.json')\n",
    "dev_path = os.path.join(file_dir, 'generated/dev_data_me.json')\n",
    "generated_schema_path = os.path.join(file_dir, 'generated/schemas_me.json')\n",
    "generated_char_path = os.path.join(file_dir, 'generated/all_chars_me.json')\n",
    "train_data = json.load(open(train_path))\n",
    "dev_data = json.load(open(dev_path))\n",
    "id2predicate, predicate2id = json.load(open(generated_schema_path))\n",
    "id2predicate = {int(i): j for i, j in id2predicate.items()}\n",
    "id2predicate[0] = \"未分类\"\n",
    "predicate2id[\"未分类\"] = 0\n",
    "id2char, char2id = json.load(open(generated_char_path))\n",
    "\n",
    "NUM_CLASSES = len(predicate2id)\n",
    "config.num_classes = NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a8fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set debug mode to True to only train on a small batch of data\n",
    "config.debug_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79073afe",
   "metadata": {},
   "source": [
    "Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b3fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "dg = BertDataGenerator(train_data, bert_tokenizer)\n",
    "T, S1, S2, K1, K2, O1, O2, attention_masks = dg.pro_res()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6357764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(T, S1, S2, K1, K2, O1, O2, attention_masks)\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_dataset,      # torch TensorDataset format\n",
    "    batch_size=BATCH_SIZE,      # mini batch size\n",
    "    shuffle=True,               # random shuffle for training\n",
    "    num_workers=1,\n",
    "    collate_fn=collate_fn,      # subprocesses for loading data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b731f1d",
   "metadata": {},
   "source": [
    "Define subject model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f976f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_model = SubjectModel(WORD_EMB_SIZE).to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print('Using', torch.cuda.device_count(), \"GPUs!\")\n",
    "    subject_model = nn.DataParallel(subject_model)\n",
    "print(\"word embeding size is\", WORD_EMB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0421d4ab",
   "metadata": {},
   "source": [
    "Define update related variables and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a2dcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(subject_model.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=LEARNING_RATE)\n",
    "loss_fn = F.binary_cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1920f682",
   "metadata": {},
   "source": [
    "Use a tensorboard writer to log training stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4c3f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%m_%d_%H_%M\")\n",
    "log_dir = os.path.join('logs', 'subject', dt_string)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "print(\"Logs are saved at:\", log_dir)\n",
    "print(\"Run this command at the current folder to launch tensorboard:\")\n",
    "print(\"tensorboard --logdir=logs/subject\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccb7708",
   "metadata": {},
   "source": [
    "Train subject model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dba797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# macos only: use this command to work around the libomp issue (multiple libs are loaded)\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step_cnt = 0 # a counter for tensorboard writer\n",
    "for i in trange(EPOCH_NUM, desc='Epoch'):\n",
    "    train_tqdm = tqdm(iter(train_loader), desc=\"Train\")\n",
    "    for step, batch in enumerate(train_tqdm):\n",
    "        tokens = batch[\"T\"].to(device) # text (in the form of index, zero-padding)\n",
    "        subject_start_pos = batch[\"K1\"].to(device) # subject start index\n",
    "        subject_end_pos = batch[\"K2\"].to(device) # subject end index\n",
    "        subject_start = batch[\"S1\"].to(device) # subject start in 1-0 vector (may have multiple subject)\n",
    "        subject_end = batch[\"S2\"].to(device) # subject end in 1-0 vector (may have multiple)\n",
    "        object_start = batch[\"O1\"].to(device) # object start in 1-0 vector (may have multiple object)\n",
    "        object_end = batch[\"O2\"].to(device) # object end in 1-0 vector (may have multiple objects)\n",
    "        att_mask = batch['masks'].to(device)\n",
    "        # predict\n",
    "        subject_preds, hidden_states = subject_model(tokens)\n",
    "        # calc loss\n",
    "        s1_loss = loss_fn(subject_preds[:,:,0], subject_start, reduction='none') # (bsz, sent_len)\n",
    "        s1_loss = torch.sum(s1_loss * att_mask) / torch.sum(att_mask) # ()\n",
    "        s2_loss = loss_fn(subject_preds[:,:,1], subject_end, reduction='none')\n",
    "        s2_loss = torch.sum(s2_loss * att_mask)/torch.sum(att_mask)\n",
    "        loss_sum = s1_loss + s2_loss\n",
    "        # loggings\n",
    "        writer.add_scalar('subject/loss', loss_sum.item(), total_step_cnt)\n",
    "        # print(loss_sum.item(), total_step_cnt)\n",
    "        total_step_cnt += 1\n",
    "        train_tqdm.set_postfix(loss=loss_sum.item())\n",
    "        #updates\n",
    "        optimizer.zero_grad()\n",
    "        loss_sum.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a535ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
