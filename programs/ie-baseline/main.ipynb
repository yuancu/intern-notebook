{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7140fa4d",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Adapted from the original `main.py`. Intergrated with AWS SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862f7db5",
   "metadata": {},
   "source": [
    "## Install dependencies\n",
    "\n",
    "This model requires torch >= 1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120acef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from data_gen import MyDevDataset, NeatDataset, dev_collate_fn, neat_collate_fn\n",
    "from model_origin import SubjectModel, ObjectModel\n",
    "import config\n",
    "from config import create_parser, predicate2id, id2predicate\n",
    "from utils import para_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba6f706",
   "metadata": {},
   "source": [
    "Define a tensorboard logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acaa682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "logname = None\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%m_%d_%H_%M\")\n",
    "if logname is None:\n",
    "    log_dir = os.path.join('logs', dt_string)\n",
    "else:\n",
    "    log_dir = os.path.join('logs', logname + '_' + dt_string)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "print(\"Logs are saved at:\", log_dir)\n",
    "print(\"Run this command at the current folder to launch tensorboard:\")\n",
    "print(\"tensorboard --logdir=logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1360d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35583900",
   "metadata": {},
   "source": [
    "Read configs from module `config.py`, and define `device`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b38325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for macOS compatibility\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "BERT_MODEL_NAME = config.bert_model_name\n",
    "LEARNING_RATE = config.learning_rate\n",
    "WORD_EMB_SIZE = config.word_emb_size # default bert embedding size\n",
    "BATCH_SIZE = config.batch_size\n",
    "BERT_DICT_LEN = config.bert_dict_len\n",
    "TRAIN_PATH = config.train_path\n",
    "DEV_PATH = config.dev_path\n",
    "NUM_CLASSES = config.num_classes\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bc85c7",
   "metadata": {},
   "source": [
    "# Download training data\n",
    "Skip the downloading step if you have alreay done it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://dataset-bj.cdn.bcebos.com/qianyan/DuIE_2_0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b913b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip -j DuIE_2_0.zip -d data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27cecbf",
   "metadata": {},
   "source": [
    "Transofm raw data to easier usable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d389da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir generated\n",
    "# !python trans.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0dbf59",
   "metadata": {},
   "source": [
    "## Load training data\n",
    "\n",
    "Load train and test data. Define their dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17538c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust batch size if needed\n",
    "# BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bc5084",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2predicate, predicate2id = config.id2predicate, config.predicate2id\n",
    "\n",
    "train_data = json.load(open(TRAIN_PATH))\n",
    "dev_data = json.load(open(DEV_PATH))\n",
    "train_dataset = NeatDataset(train_data, BERT_MODEL_NAME)\n",
    "test_dataset = MyDevDataset(dev_data, BERT_MODEL_NAME)\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,      # torch TensorDataset format\n",
    "    batch_size=BATCH_SIZE,      # mini batch size\n",
    "    shuffle=True,               # random shuffle for training\n",
    "    num_workers=2,\n",
    "    collate_fn=neat_collate_fn,      # subprocesses for loading data\n",
    "    multiprocessing_context='spawn',\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,      # torch TensorDataset format\n",
    "    batch_size=BATCH_SIZE,      # mini batch size\n",
    "    shuffle=True,               # random shuffle for training\n",
    "    num_workers=2,\n",
    "    collate_fn=dev_collate_fn,      # subprocesses for loading data\n",
    "    multiprocessing_context='spawn',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0f3eba",
   "metadata": {},
   "source": [
    "### Define models\n",
    "Data are parallimised  to multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca95f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_model = SubjectModel(BERT_DICT_LEN, WORD_EMB_SIZE).to(device)\n",
    "object_model = ObjectModel(WORD_EMB_SIZE, NUM_CLASSES).to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print('Using', torch.cuda.device_count(), \"GPUs!\")\n",
    "    subject_model = nn.DataParallel(subject_model)\n",
    "    object_model = nn.DataParallel(object_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e954f8",
   "metadata": {},
   "source": [
    "### Load model if needed\n",
    "Uncomment lines below to load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100f62e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoint_epoch = 195 # 210 is saved in repo\n",
    "model_dir = 'save'\n",
    "weight_name = 'att1'\n",
    "subject_model.load_state_dict(torch.load(f\"./{model_dir}/subject_{weight_name}_{breakpoint_epoch}\", map_location=device))\n",
    "object_model.load_state_dict(torch.load(f\"./{model_dir}/object_{weight_name}_{breakpoint_epoch}\", map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7207fd",
   "metadata": {},
   "source": [
    "### Define loss metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8308b3fd",
   "metadata": {},
   "source": [
    "**Run this after reloading the model and before training**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e74189",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = subject_model.parameters()\n",
    "params = list(params) + list(object_model.parameters())\n",
    "print(\"Using learning rate\", LEARNING_RATE)\n",
    "optimizer = torch.optim.Adam(params, lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e195da",
   "metadata": {},
   "source": [
    "### Define training and evaluate scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cee221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(subject_model, object_model, device, train_loader, optimizer, epoch, writer=None, log_interval=10):\n",
    "    subject_model.train()\n",
    "    object_model.train()\n",
    "    train_tqdm = tqdm(enumerate(train_loader), desc=\"Train\")\n",
    "    for step, batch in train_tqdm:\n",
    "        token_ids, attention_masks, subject_ids, subject_labels, object_labels = batch\n",
    "        token_ids, attention_masks, subject_ids, subject_labels, object_labels = \\\n",
    "            token_ids.to(device), attention_masks.to(device), subject_ids.to(device), \\\n",
    "            subject_labels.to(device), object_labels.to(device)\n",
    "        # predict\n",
    "        subject_preds, hidden_states = subject_model(token_ids, attention_mask=attention_masks)\n",
    "        object_preds = object_model(hidden_states, subject_ids, attention_masks)\n",
    "        # calc loss\n",
    "        subject_loss = F.binary_cross_entropy(subject_preds, subject_labels, reduction='none') # (bsz, sent_len)\n",
    "        attention_masks = attention_masks.unsqueeze(dim=2)\n",
    "        subject_loss = torch.sum(subject_loss * attention_masks) / torch.sum(attention_masks) # ()\n",
    "        object_loss = F.binary_cross_entropy(object_preds, object_labels, reduction='none') # (bsz, sent_len, n_classes, 2)\n",
    "        object_loss = torch.mean(object_loss, dim=2) # (bsz, sent_len, 2)\n",
    "        object_loss = torch.sum(object_loss * attention_masks) / torch.sum(attention_masks) # ()\n",
    "        loss_sum = subject_loss + object_loss * 10\n",
    "        train_tqdm.set_postfix(loss=loss_sum.item())\n",
    "        #updates\n",
    "        optimizer.zero_grad()\n",
    "        loss_sum.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            exists_subject = subject_labels.sum().item()\n",
    "            correct_subject = torch.logical_and(subject_preds > 0.6, subject_labels > 0.6).sum().item()\n",
    "            exists_object = object_labels.sum().item()\n",
    "            correct_object = torch.logical_and(object_preds > 0.5, object_labels > 0.5).sum().item()\n",
    "\n",
    "            if step % log_interval == 0:\n",
    "                print(f\"epoch {epoch}, step: {step}, loss: {loss_sum.item()}, subject_recall: {correct_subject}/{exists_subject}, object_recall: {correct_object}/{exists_object}\")\n",
    "                if writer:\n",
    "                    writer.add_scalar('train/loss', loss_sum.item(), step + epoch * len(train_loader))\n",
    "                    writer.add_scalar('train/loss_subject', subject_loss.item(), step + epoch * len(train_loader))\n",
    "                    writer.add_scalar('train/loss_object', object_loss.item(), step + epoch * len(train_loader))\n",
    "                    writer.add_scalar('train/recall_subject', correct_subject/exists_subject, step + epoch * len(train_loader))\n",
    "                    writer.add_scalar('train/recall_object', correct_object/exists_object, step + epoch * len(train_loader))\n",
    "\n",
    "\n",
    "def evaluate(subject_model, object_model, loader, id2predicate, epoch, writer=None):\n",
    "    subject_model.eval()\n",
    "    object_model.eval()\n",
    "    f1, precision, recall = para_eval(subject_model, object_model, loader, id2predicate, epoch=epoch, writer=writer)\n",
    "    print(f\"Eval epoch {epoch}: f1: {f1}, precision: {precision}, recall: {recall}\")\n",
    "    if writer:\n",
    "        writer.add_scalar('eval/f1', f1, epoch)\n",
    "        writer.add_scalar('eval/precision', precision, epoch)\n",
    "        writer.add_scalar('eval/recall', recall, epoch)\n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0db1bd",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba33f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0\n",
    "best_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fc767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_epoch = 0\n",
    "\n",
    "# If you have loaded model from a break point, this part set the starting epoch from the break point.\n",
    "try:\n",
    "    breakpoint_epoch\n",
    "except NameError:\n",
    "    print(\"breakpoint epoch not defined, start training from epoch 0\")\n",
    "else:\n",
    "    print(\"continue training from epoch\", breakpoint_epoch)\n",
    "    starting_epoch = breakpoint_epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab86758",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589dc504",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(starting_epoch, epoch_num):\n",
    "    train(subject_model, object_model, device, train_loader, optimizer, e, writer=writer, log_interval=10)\n",
    "    f1, precision, recall = evaluate(subject_model, object_model, test_loader, id2predicate, e, writer)\n",
    "    \n",
    "    if e % 5 == 0:\n",
    "        torch.save(subject_model.state_dict(), f\"save/subject_{args.logname}_{e}\")\n",
    "        torch.save(object_model.state_dict(), f\"save/object_{args.logname}_{e}\")\n",
    "\n",
    "    if f1 >= best_f1:\n",
    "        best_f1 = f1\n",
    "        best_epoch = i\n",
    "\n",
    "    print('f1: %.4f, precision: %.4f, recall: %.4f, bestf1: %.4f, bestepoch: %d \\n ' % (\n",
    "        f1, precision, recall, best_f1, best_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0692c9",
   "metadata": {},
   "source": [
    "## Test the trained model on some texts\n",
    "Extract plain model from Dataparalell if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b6d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    subject_model = subject_model.module\n",
    "    object_model = object_model.module\n",
    "    print(\"extracted model from DataParalell wrapper\")\n",
    "except:\n",
    "    print(\"models are not wrapped by DataParalell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbee814",
   "metadata": {},
   "source": [
    "Examine the model on some test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f699abe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "examine_train_loader = DataLoader(\n",
    "    dataset=train_dataset,    \n",
    "    batch_size=2,    \n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=neat_collate_fn,\n",
    ")\n",
    "examine_test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    collate_fn=dev_collate_fn,\n",
    "    multiprocessing_context='spawn',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe89dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import extract_spoes\n",
    "\n",
    "to_print = 4\n",
    "for step in range(to_print):\n",
    "    texts, tokens, spoes, att_masks, offset_mappings = next(iter(examine_test_loader))\n",
    "    print('Text: ', texts)\n",
    "    print('Predicted SPOs:', extract_spoes(texts, tokens, offset_mappings, subject_model, object_model, id2predicate, attention_mask=att_masks))\n",
    "    print('Gold SPOs:', spoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beb4892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model\n",
    "with torch.no_grad():\n",
    "    token_ids, attention_masks, subject_ids, subject_labels, object_labels = next(iter(examine_train_loader))\n",
    "    writer.add_graph(subject_model, (token_ids, attention_masks))\n",
    "    _, hidden_states = subject_model(token_ids, attention_mask=attention_masks)\n",
    "    writer.add_graph(object_model, (hidden_states, subject_ids, attention_masks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d24224",
   "metadata": {},
   "source": [
    "# Find the best model saved\n",
    "First iterate trough 0 to 195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf870f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_model = SubjectModel(BERT_DICT_LEN, WORD_EMB_SIZE).to(device)\n",
    "object_model = ObjectModel(WORD_EMB_SIZE, NUM_CLASSES).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbed332",
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoint_epoch = 195 # 210 is saved in repo\n",
    "model_dir = 'save'\n",
    "weight_name = 'att1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011e8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = 0\n",
    "best_f1 = 0\n",
    "for e in range(0, epoch_num, 5):\n",
    "    subject_model.load_state_dict(torch.load(f\"./{model_dir}/subject_{weight_name}_{e}\", map_location=device))\n",
    "    object_model.load_state_dict(torch.load(f\"./{model_dir}/object_{weight_name}_{e}\", map_location=device))\n",
    "    f1, precision, recall = evaluate(subject_model, object_model, test_loader, id2predicate, e, writer)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_epoch = e\n",
    "    print('Epoch %d: f1: %.4f, precision: %.4f, recall: %.4f, bestf1: %.4f, bestepoch: %d \\n ' % (\n",
    "        e, f1, precision, recall, best_f1, best_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd731604",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
