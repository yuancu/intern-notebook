{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47afe45e",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Adapted from the original `main.py`. Intergrated with AWS SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcf1860",
   "metadata": {},
   "source": [
    "## Install dependencies\n",
    "(actually only tqdm, since other packages are pre-installed in aws pytorch environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9760b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c462c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from random import choice\n",
    "from tqdm import tqdm\n",
    "import model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "#import data_prepare\n",
    "import os\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423ec3d",
   "metadata": {},
   "source": [
    "Define a tensorboard logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe2f9f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bbb904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad835d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for macOS compatibility\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "CHAR_SIZE = 128\n",
    "SENT_LENGTH = 4\n",
    "HIDDEN_SIZE = 64\n",
    "EPOCH_NUM = 400\n",
    "BATCH_SIZE = 5096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d52a3e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ec1fda",
   "metadata": {},
   "source": [
    "Helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d4a03ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_now_time():\n",
    "    a = time.time()\n",
    "    return time.ctime(a)\n",
    "\n",
    "\n",
    "def seq_padding(X):\n",
    "    L = [len(x) for x in X]\n",
    "    ML = max(L)\n",
    "    # print(\"ML\",ML)\n",
    "    return [x + [0] * (ML - len(x)) for x in X]\n",
    "\n",
    "\n",
    "def seq_padding_vec(X):\n",
    "    L = [len(x) for x in X]\n",
    "    ML = max(L)\n",
    "    # print(\"ML\",ML)\n",
    "    return [x + [[1, 0]] * (ML - len(x)) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2f817a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, data, batch_size=64):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.steps = len(self.data) // self.batch_size\n",
    "        if len(self.data) % self.batch_size != 0:\n",
    "            self.steps += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "    def pro_res(self):\n",
    "        idxs = list(range(len(self.data)))\n",
    "        # print(idxs)\n",
    "        np.random.shuffle(idxs)\n",
    "        T, S1, S2, K1, K2, O1, O2, = [], [], [], [], [], [], []\n",
    "        for i in idxs:\n",
    "            d = self.data[i]\n",
    "            text = d['text']\n",
    "            items = {}\n",
    "            items = defaultdict(list)\n",
    "            for sp in d['spo_list']:\n",
    "                subjectid = text.find(sp[0])\n",
    "                objectid = text.find(sp[2])\n",
    "                if subjectid != -1 and objectid != -1:\n",
    "                    key = (subjectid, subjectid+len(sp[0])) # key is the span(start, end) of the subject\n",
    "                    # items is {(S_start, S_end): list of (O_start_pos, O_end_pos, predicate_id)}\n",
    "                    items[key].append(\n",
    "                        (objectid, objectid+len(sp[2]), predicate2id[sp[1]]))\n",
    "            if items:\n",
    "                # T is list of text tokens(ids)\n",
    "                T.append([char2id.get(c, 1) for c in text])  # 1是unk，0是padding\n",
    "         \n",
    "                # s1: one-hot vector where start of subject is 1\n",
    "                # s2: one-hot vector where end of subject is 1\n",
    "                s1, s2 = [0] * len(text), [0] * len(text)\n",
    "                for j in items:\n",
    "                    s1[j[0]] = 1\n",
    "                    s2[j[1]-1] = 1\n",
    "                # print(items.keys())\n",
    "                # k1, k2: randomly sampled (S_start, S_end) pair?\n",
    "                k1, k2 = choice(list(items.keys()))\n",
    "                # o1: zero vector, the start of each O is marked with its predicate ID\n",
    "                # o2: zero vector, the end of each O is marked with its predicate ID\n",
    "                o1, o2 = [0] * len(text), [0] * len(text)  # 0是unk类（共49+1个类）\n",
    "                for j in items[(k1, k2)]:\n",
    "                    o1[j[0]] = j[2]\n",
    "                    o2[j[1]-1] = j[2]\n",
    "                S1.append(s1)\n",
    "                S2.append(s2)\n",
    "                K1.append([k1])\n",
    "                K2.append([k2-1])\n",
    "                O1.append(o1)\n",
    "                O2.append(o2)\n",
    "\n",
    "        T = np.array(seq_padding(T))\n",
    "        S1 = np.array(seq_padding(S1))\n",
    "        S2 = np.array(seq_padding(S2))\n",
    "        O1 = np.array(seq_padding(O1))\n",
    "        O2 = np.array(seq_padding(O2))\n",
    "        K1, K2 = np.array(K1), np.array(K2)\n",
    "        return [T, S1, S2, K1, K2, O1, O2]\n",
    "\n",
    "\n",
    "class MyDataset(Data.Dataset):\n",
    "    \"\"\"\n",
    "        下载数据、初始化数据，都可以在这里完成\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, _T, _S1, _S2, _K1, _K2, _O1, _O2):\n",
    "        # xy = np.loadtxt('../dataSet/diabetes.csv.gz', delimiter=',', dtype=np.float32) # 使用numpy读取数据\n",
    "        self.x_data = _T\n",
    "        self.y1_data = _S1\n",
    "        self.y2_data = _S2\n",
    "        self.k1_data = _K1\n",
    "        self.k2_data = _K2\n",
    "        self.o1_data = _O1\n",
    "        self.o2_data = _O2\n",
    "        self.len = len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y1_data[index], self.y2_data[index], self.k1_data[index], self.k2_data[index], self.o1_data[index], self.o2_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    t = np.array([item[0] for item in data], np.int32)\n",
    "    s1 = np.array([item[1] for item in data], np.int32)\n",
    "    s2 = np.array([item[2] for item in data], np.int32)\n",
    "    k1 = np.array([item[3] for item in data], np.int32)\n",
    "\n",
    "    k2 = np.array([item[4] for item in data], np.int32)\n",
    "    o1 = np.array([item[5] for item in data], np.int32)\n",
    "    o2 = np.array([item[6] for item in data], np.int32)\n",
    "    return {\n",
    "        'T': torch.LongTensor(t),  # targets_i\n",
    "        'S1': torch.FloatTensor(s1),\n",
    "        'S2': torch.FloatTensor(s2),\n",
    "        'K1': torch.LongTensor(k1),\n",
    "        'K2': torch.LongTensor(k2),\n",
    "        'O1': torch.LongTensor(o1),\n",
    "        'O2': torch.LongTensor(o2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "debe94f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_items(text_in, s_m, po_m):\n",
    "    R = []\n",
    "    _s = [char2id.get(c, 1) for c in text_in]\n",
    "    _s = np.array([_s])\n",
    "    _k1, _k2, t, t_max, mask = s_m(torch.LongTensor(_s).to(device))\n",
    "    _k1, _k2 = _k1[0, :, 0], _k2[0, :, 0]\n",
    "    _kk1s = []\n",
    "    for i, _kk1 in enumerate(_k1):\n",
    "        if _kk1 > 0.5:\n",
    "            _subject = ''\n",
    "            for j, _kk2 in enumerate(_k2[i:]):\n",
    "                if _kk2 > 0.5:\n",
    "                    _subject = text_in[i: i+j+1]\n",
    "                    break\n",
    "            if _subject:\n",
    "                _k1, _k2 = torch.LongTensor([[i]]), torch.LongTensor(\n",
    "                    [[i+j]])  # np.array([i]), np.array([i+j])\n",
    "                _o1, _o2 = po_m(t.to(device), t_max.to(\n",
    "                    device), _k1.to(device), _k2.to(device))\n",
    "                _o1, _o2 = _o1.cpu().data.numpy(), _o2.cpu().data.numpy()\n",
    "\n",
    "                _o1, _o2 = np.argmax(_o1[0], 1), np.argmax(_o2[0], 1)\n",
    "\n",
    "                for i, _oo1 in enumerate(_o1):\n",
    "                    if _oo1 > 0:\n",
    "                        for j, _oo2 in enumerate(_o2[i:]):\n",
    "                            if _oo2 == _oo1:\n",
    "                                _object = text_in[i: i+j+1]\n",
    "                                _predicate = id2predicate[_oo1]\n",
    "                                # print((_subject, _predicate, _object))\n",
    "                                R.append((_subject, _predicate, _object))\n",
    "                                break\n",
    "        _kk1s.append(_kk1.data.cpu().numpy())\n",
    "    _kk1s = np.array(_kk1s)\n",
    "    return list(set(R))\n",
    "\n",
    "def para_extract_items(loader_res):\n",
    "    t_s = loader_res[\"T\"].to(device)\n",
    "    k1 = loader_res[\"K1\"].to(device)\n",
    "    k2 = loader_res[\"K2\"].to(device)\n",
    "    s1 = loader_res[\"S1\"].to(device)\n",
    "    s2 = loader_res[\"S2\"].to(device)\n",
    "    o1 = loader_res[\"O1\"].to(device)\n",
    "    o2 = loader_res[\"O2\"].to(device)\n",
    "\n",
    "    ps_1, ps_2, t, t_max, mask = s_m(t_s)\n",
    "\n",
    "    t, t_max, k1, k2 = t.to(device), t_max.to(\n",
    "        device), k1.to(device), k2.to(device)\n",
    "    po_1, po_2 = po_m(t, t_max, k1, k2)\n",
    "\n",
    "    ps_1 = ps_1.to(device)\n",
    "    ps_2 = ps_2.to(device)\n",
    "    po_1 = po_1.to(device)\n",
    "    po_2 = po_2.to(device)\n",
    "\n",
    "    s1 = torch.unsqueeze(s1, 2)\n",
    "    s2 = torch.unsqueeze(s2, 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "def para_evaluate():\n",
    "    A, B, C = 1e-10, 1e-10, 1e-10\n",
    "    cnt = 0\n",
    "    s_m.eval()\n",
    "    po_m.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, loader_res in tqdm(iter(enumerate(loader))):\n",
    "            R = set(para_extract_items(loader_res))\n",
    "            T = None\n",
    "            A += len(R & T)\n",
    "            B += len(R)\n",
    "            C += len(T)\n",
    "            cnt += 1\n",
    "    return 2 * A / (B + C), A / B, A / C\n",
    "    \n",
    "\n",
    "def evaluate(s_m, po_m, dev_data):\n",
    "    A, B, C = 1e-10, 1e-10, 1e-10\n",
    "    cnt = 0\n",
    "    s_m.eval()\n",
    "    po_m.eval()\n",
    "    for d in tqdm(iter(dev_data)):\n",
    "        if cnt > 1000:\n",
    "            break\n",
    "        R = set(extract_items(d['text'], s_m, po_m))\n",
    "        T = set([tuple(i) for i in d['spo_list']])\n",
    "        A += len(R & T)\n",
    "        B += len(R)\n",
    "        C += len(T)\n",
    "        # if cnt % 1000 == 0:\n",
    "        #     print('iter: %d f1: %.4f, precision: %.4f, recall: %.4f\\n' % (cnt, 2 * A / (B + C), A / B, A / C))\n",
    "        cnt += 1\n",
    "    return 2 * A / (B + C), A / B, A / C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75f9db3",
   "metadata": {},
   "source": [
    "# Download training data\n",
    "Skip the downloading step if you have alreay done it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ee2a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://dataset-bj.cdn.bcebos.com/qianyan/DuIE_2_0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d103e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip -j DuIE_2_0.zip -d data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137650d7",
   "metadata": {},
   "source": [
    "Transofm raw data to easier usable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "472d4451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir generated\n",
    "# !python trans.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c7996f",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05365ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'generated/train_data_me.json'\n",
    "dev_path = 'generated/dev_data_me.json'\n",
    "generated_schema_path =  'generated/schemas_me.json'\n",
    "generated_char_path = 'generated/all_chars_me.json'\n",
    "train_data = json.load(open(train_path))\n",
    "dev_data = json.load(open(dev_path))\n",
    "id2predicate, predicate2id = json.load(open(generated_schema_path))\n",
    "id2predicate = {int(i): j for i, j in id2predicate.items()}\n",
    "id2char, char2id = json.load(open(generated_char_path))\n",
    "num_classes = len(id2predicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DataGenerator(train_data)\n",
    "T, S1, S2, K1, K2, O1, O2 = dg.pro_res()\n",
    "# print(\"len\",len(T))\n",
    "\n",
    "torch_dataset = MyDataset(T, S1, S2, K1, K2, O1, O2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3c3828",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,      # torch TensorDataset format\n",
    "    batch_size=BATCH_SIZE,      # mini batch size\n",
    "    shuffle=True,               # random shuffle for training\n",
    "    num_workers=64,\n",
    "    collate_fn=collate_fn,      # subprocesses for loading data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d027b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dg = DataGenerator(dev_data)\n",
    "T_dev, S1_dev, S2_dev, K1_dev, K2_dev, O1_dev, O2_dev = dev_dg.pro_res()\n",
    "dev_dataset = MyDataset(T_dev, S1_dev, S2_dev, K1_dev, K2_dev, O1_dev, O2_dev)\n",
    "dev_loader = Data.DataLoader(\n",
    "    dataset=dev_dataset,      # torch TensorDataset format\n",
    "    batch_size=BATCH_SIZE,      # mini batch size\n",
    "    shuffle=True,               # random shuffle for training\n",
    "    num_workers=64,\n",
    "    collate_fn=collate_fn,      # subprocesses for loading data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72190672",
   "metadata": {},
   "source": [
    "### Define model and loss\n",
    "Data are parallimised  to multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab948c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_m = model.s_model(len(char2id)+2, CHAR_SIZE, HIDDEN_SIZE)\n",
    "po_m = model.po_model(len(char2id)+2, CHAR_SIZE, HIDDEN_SIZE, 49)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print('Using', torch.cuda.device_count(), \"GPUs!\")\n",
    "    s_m = nn.DataParallel(s_m)\n",
    "    po_m = nn.DataParallel(po_m)\n",
    "\n",
    "s_m = s_m.to(device)\n",
    "po_m = po_m.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5205fa89",
   "metadata": {},
   "source": [
    "### Load model if needed\n",
    "Uncomment lines below to load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c1705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_dir, epoch, device):\n",
    "    s_m = torch.load(os.path.join(model_dir, \"s_{}.pkl\".format(epoch)), map_location=device)\n",
    "    po_m = torch.load(os.path.join(model_dir, \"po_{}.pkl\".format(epoch)), map_location=device)\n",
    "    # reload the model with DataParallel (this will \n",
    "    # be helpful when num of GPUs changes)\n",
    "    s_m = nn.DataParallel(s_m.module)\n",
    "    po_m = nn.DataParallel(po_m.module)\n",
    "    return s_m, po_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a7a921",
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoint_epoch = 210\n",
    "model_dir = 'models_real'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7415c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_m, po_m = load_model(model_dir, breakpoint_epoch, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c65744",
   "metadata": {},
   "source": [
    "### Define loss metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23af6ebe",
   "metadata": {},
   "source": [
    "**Run this after reloading the model and before training**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04f8a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(s_m.parameters())\n",
    "params += list(po_m.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss().to(device)\n",
    "b_loss = torch.nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3ba258",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624078a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0\n",
    "best_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32928b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [02:15,  3.98s/it]\n",
      "1001it [00:16, 59.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 210 loss: tensor(0.0265, device='cuda:0')\n",
      "epoch 210 used 155.96729707717896 seconds (with bsz=5096)\n",
      "f1: 0.5974, precision: 0.7745, recall: 0.4862, bestf1: 0.5974, bestepoch: 210 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "34it [02:15,  3.98s/it]\n",
      "1001it [00:16, 61.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 211 loss: tensor(0.0265, device='cuda:0')\n",
      "epoch 211 used 155.5171353816986 seconds (with bsz=5096)\n",
      "f1: 0.5858, precision: 0.7856, recall: 0.4670, bestf1: 0.5974, bestepoch: 210 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10it [00:40,  4.03s/it]Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/queues.py\", line 230, in _feed\n",
      "    close()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "34it [02:15,  3.99s/it]\n",
      "1001it [00:16, 61.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 212 loss: tensor(0.0257, device='cuda:0')\n",
      "epoch 212 used 155.75757551193237 seconds (with bsz=5096)\n",
      "f1: 0.5880, precision: 0.7826, recall: 0.4710, bestf1: 0.5974, bestepoch: 210 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "34it [02:15,  3.98s/it]\n",
      "1001it [00:16, 61.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 213 loss: tensor(0.0262, device='cuda:0')\n",
      "epoch 213 used 155.47865533828735 seconds (with bsz=5096)\n",
      "f1: 0.5910, precision: 0.7761, recall: 0.4772, bestf1: 0.5974, bestepoch: 210 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "34it [02:15,  3.99s/it]\n",
      "1001it [00:16, 60.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 214 loss: tensor(0.0254, device='cuda:0')\n",
      "epoch 214 used 156.18386721611023 seconds (with bsz=5096)\n",
      "f1: 0.5930, precision: 0.7684, recall: 0.4828, bestf1: 0.5974, bestepoch: 210 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "34it [02:16,  4.00s/it]\n",
      "1001it [00:16, 61.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 215 loss: tensor(0.0268, device='cuda:0')\n",
      "epoch 215 used 156.4516041278839 seconds (with bsz=5096)\n",
      "f1: 0.5883, precision: 0.7670, recall: 0.4772, bestf1: 0.5974, bestepoch: 210 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "34it [02:15,  3.99s/it]\n",
      "1001it [00:16, 60.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 216 loss: tensor(0.0266, device='cuda:0')\n",
      "epoch 216 used 156.2406644821167 seconds (with bsz=5096)\n",
      "f1: 0.5758, precision: 0.7671, recall: 0.4608, bestf1: 0.5974, bestepoch: 210 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [00:44,  4.03s/it]"
     ]
    }
   ],
   "source": [
    "starting_epoch = 210\n",
    "\n",
    "# try:\n",
    "#     breakpoint_epoch\n",
    "# except NameError:\n",
    "#     print(\"breakpoint epoch not defined, start training from epoch 0\")\n",
    "# else:\n",
    "#     print(\"continue training from epoch\", breakpoint_epoch)\n",
    "#     starting_epoch = breakpoint_epoch\n",
    "\n",
    "\n",
    "\n",
    "for i in range(starting_epoch, EPOCH_NUM):\n",
    "    epoch_start_time = time.time()\n",
    "    s_m.train()\n",
    "    po_m.train()\n",
    "    for step, loader_res in tqdm(iter(enumerate(loader))):\n",
    "        # print(get_now_time())\n",
    "        t_s = loader_res[\"T\"].to(device)\n",
    "        k1 = loader_res[\"K1\"].to(device)\n",
    "        k2 = loader_res[\"K2\"].to(device)\n",
    "        s1 = loader_res[\"S1\"].to(device)\n",
    "        s2 = loader_res[\"S2\"].to(device)\n",
    "        o1 = loader_res[\"O1\"].to(device)\n",
    "        o2 = loader_res[\"O2\"].to(device)\n",
    "\n",
    "        ps_1, ps_2, t, t_max, mask = s_m(t_s)\n",
    "\n",
    "        t, t_max, k1, k2 = t.to(device), t_max.to(\n",
    "            device), k1.to(device), k2.to(device)\n",
    "        po_1, po_2 = po_m(t, t_max, k1, k2)\n",
    "\n",
    "        ps_1 = ps_1.to(device)\n",
    "        ps_2 = ps_2.to(device)\n",
    "        po_1 = po_1.to(device)\n",
    "        po_2 = po_2.to(device)\n",
    "\n",
    "        s1 = torch.unsqueeze(s1, 2)\n",
    "        s2 = torch.unsqueeze(s2, 2)\n",
    "\n",
    "        s1_loss = b_loss(ps_1, s1)\n",
    "        s1_loss = torch.sum(s1_loss.mul(mask))/torch.sum(mask)\n",
    "        s2_loss = b_loss(ps_2, s2)\n",
    "        s2_loss = torch.sum(s2_loss.mul(mask))/torch.sum(mask)\n",
    "\n",
    "        po_1 = po_1.permute(0, 2, 1)\n",
    "        po_2 = po_2.permute(0, 2, 1)\n",
    "\n",
    "        o1_loss = loss(po_1, o1)\n",
    "        o1_loss = torch.sum(o1_loss.mul(mask[:, :, 0])) / torch.sum(mask)\n",
    "        o2_loss = loss(po_2, o2)\n",
    "        o2_loss = torch.sum(o2_loss.mul(mask[:, :, 0])) / torch.sum(mask)\n",
    "\n",
    "        loss_sum = 2.5 * (s1_loss + s2_loss) + (o1_loss + o2_loss)\n",
    "\n",
    "        # if step % 500 == 0:\n",
    "        # \ttorch.save(s_m, 'models_real/s_'+str(step)+\"epoch_\"+str(i)+'.pkl')\n",
    "        # \ttorch.save(po_m, 'models_real/po_'+str(step)+\"epoch_\"+str(i)+'.pkl')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_sum.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    torch.save(s_m, 'models_real/s_'+str(i)+'.pkl')\n",
    "    torch.save(po_m, 'models_real/po_'+str(i)+'.pkl')\n",
    "    f1, precision, recall = evaluate(s_m, po_m, dev_data)\n",
    "\n",
    "    print(\"epoch:\", i, \"loss:\", loss_sum.data)\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_time_elapsed = epoch_end_time - epoch_start_time\n",
    "    print(\"epoch {} used {} seconds (with bsz={})\".format(i, epoch_time_elapsed, BATCH_SIZE))\n",
    "    writer.add_scalar('Loss/train', loss_sum.data, i)\n",
    "    writer.add_scalar('f1', f1, i)\n",
    "    writer.add_scalar('precision', precision, i)\n",
    "    writer.add_scalar('recall', recall, i)\n",
    "\n",
    "    if f1 >= best_f1:\n",
    "        best_f1 = f1\n",
    "        best_epoch = i\n",
    "\n",
    "    print('f1: %.4f, precision: %.4f, recall: %.4f, bestf1: %.4f, bestepoch: %d \\n ' % (\n",
    "        f1, precision, recall, best_f1, best_epoch))\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb3262bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62834793",
   "metadata": {},
   "source": [
    "## Test the trained model on some texts\n",
    "Extract plain model from Dataparalell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a8807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_m = s_m.module\n",
    "po_m = po_m.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a37f758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  《步步惊心》改编自著名作家桐华的同名清穿小说《甄嬛传》改编自流潋紫所著的同名小说电视剧《何以笙箫默》改编自顾漫同名小说《花千骨》改编自fresh果果同名小说《裸婚时代》是月影兰析创作的一部情感小说《琅琊榜》是根据海宴同名网络小说改编电视剧《宫锁心玉》，又名《宫》《雪豹》，该剧改编自网络小说《特战先驱》《我是特种兵》由红遍网络的小说《最后一颗子弹留给我》改编电视剧《来不及说我爱你》改编自匪我思存同名小说《来不及说我爱你》\n",
      "Predicted SPOs:  [('步步惊心', '作者', '桐华'), ('步步惊心', '改编自', '来不及说我爱你'), ('步步惊心', '改编自', '步步惊心》改编自著名作家桐华的同名清穿小说《甄嬛传'), ('步步惊心', '改编自', '特战先驱'), ('步步惊心', '改编自', '花千骨'), ('步步惊心', '改编自', '何以笙箫默'), ('步步惊心', '改编自', '最后一颗子弹留给我'), ('步步惊心', '改编自', '裸婚时代'), ('步步惊心', '改编自', '甄嬛传')]\n",
      "Ground Truth SPOs:  [['何以笙箫默', '作者', '顾漫'], ['我是特种兵', '改编自', '最后一颗子弹留给我'], ['步步惊心', '作者', '桐华'], ['甄嬛传', '作者', '流潋紫'], ['花千骨', '作者', 'fresh果果'], ['裸婚时代', '作者', '月影兰析'], ['琅琊榜', '作者', '海宴'], ['雪豹', '改编自', '特战先驱'], ['来不及说我爱你', '改编自', '来不及说我爱你'], ['来不及说我爱你', '作者', '匪我思存']]\n",
      "Text:  摩尔多瓦共和国（摩尔多瓦语：Republica Moldova，英语：Republic of Moldova），简称摩尔多瓦，是位于东南欧的内陆国，与罗马尼亚和乌克兰接壤，首都基希讷乌\n",
      "Predicted SPOs:  []\n",
      "Ground Truth SPOs:  [['摩尔多瓦', '首都', '基希讷乌']]\n",
      "Text:  2月19日，96岁的资深演员侯焕玲离世，候婆婆一生未嫁，但一直热爱电影，她曾在《回魂夜》和《喜剧之王》等电影饰演婆婆一角，而临终前候婆婆一直说，自己好喜欢电影，好喜欢周星驰\n",
      "Predicted SPOs:  [('喜剧之王', '主演', '侯焕玲')]\n",
      "Ground Truth SPOs:  [['喜剧之王', '编剧', '周星驰']]\n",
      "Text:  这件婚事原本与陈国峻无关，但陈国峻却“欲求配而无由，夜间乃潜入天城公主所居通之\n",
      "Predicted SPOs:  []\n",
      "Ground Truth SPOs:  [['天城公主', '丈夫', '国峻'], ['国峻', '妻子', '天城公主']]\n",
      "Text:  情人节大盘约在4亿特工票房1.32拉拉蓝1.05其他没所谓了@0216幻影9527 @朦胧之于暖春 @Jqpiero @娶个明星这么难 @星爷最低调\n",
      "Predicted SPOs:  []\n",
      "Ground Truth SPOs:  [['情人节', '票房', '4亿']]\n",
      "Text:  《父老乡亲》是由是由由中国人民解放军海政文工团创作的军旅歌曲，石顺义作词，王锡仁作曲，范琳琳演唱\n",
      "Predicted SPOs:  [('父老乡亲', '歌手', '范琳琳'), ('父老乡亲', '作词', '石顺义'), ('父老乡亲', '作曲', '王锡仁')]\n",
      "Ground Truth SPOs:  [['父老乡亲', '歌手', '范琳琳'], ['石顺义', '国籍', '中国'], ['父老乡亲', '作词', '石顺义'], ['父老乡亲', '作曲', '王锡仁']]\n",
      "Text:  2019年2月25日和26日，温氏股份实控人之一、前任董事长温鹏程之妻伍翠珍分别减持公司股票608万股和256万股，成交均价分别为30.78元/股和30.02元/股，共计套现约2.64亿元\n",
      "Predicted SPOs:  [('温鹏程', '妻子', '伍翠珍')]\n",
      "Ground Truth SPOs:  [['温氏股份', '董事长', '温鹏程'], ['伍翠珍', '丈夫', '温鹏程'], ['温鹏程', '妻子', '伍翠珍']]\n",
      "Text:  宋竹范，口腔医生，女，宋竹范主任医师毕业于佳木斯医学院，在国内三甲医院从事口腔科临床工作三十余年，有丰富的口腔科临床工作经验，熟练掌握口腔内科、口腔外科、儿童口腔科各种常见病及多发病的诊治，以及多项口腔矫形技术\n",
      "Predicted SPOs:  [('宋竹范', '毕业院校', '佳木斯医学院')]\n",
      "Ground Truth SPOs:  [['宋竹范', '毕业院校', '佳木斯医学院']]\n",
      "Text:  由江苏艺星影视文化传播有限公司投资，演员赵荀、傅程鹏、程愫、侯梦莎、任柯诺、安雅萍、杨舒、张进、杨山等主演的大型谍战题材电视剧《与狼共舞2》正在江苏卫视\n",
      "Predicted SPOs:  [('与狼共舞2', '主演', '安雅萍'), ('与狼共舞2', '主演', '任柯诺'), ('与狼共舞2', '主演', '张进'), ('与狼共舞2', '主演', '侯梦莎'), ('与狼共舞2', '主演', '傅程鹏'), ('与狼共舞2', '主演', '赵荀'), ('与狼共舞2', '主演', '程愫'), ('与狼共舞2', '主演', '杨舒'), ('与狼共舞2', '主演', '杨山')]\n",
      "Ground Truth SPOs:  [['与狼共舞2', '主演', '赵荀'], ['与狼共舞2', '主演', '侯梦莎'], ['与狼共舞2', '主演', '任柯诺'], ['与狼共舞2', '主演', '程愫'], ['与狼共舞2', '主演', '傅程鹏'], ['与狼共舞2', '主演', '安雅萍'], ['与狼共舞2', '主演', '杨舒'], ['与狼共舞2', '主演', '张进']]\n",
      "Text:  科库雷克(RadovanKocurek),出生于1986年2月12日，捷克国籍，身高179厘米，体重72公斤，场上位置前锋，现在效力于贾洛内足球俱乐部\n",
      "Predicted SPOs:  [('科库雷克', '国籍', '捷克')]\n",
      "Ground Truth SPOs:  [['科库雷克', '国籍', '捷克']]\n",
      "Text:  《外国民间歌曲选》是2004年人民音乐出版社出版的图书，作者是温恒泰\n",
      "Predicted SPOs:  [('外国民间歌曲选', '作者', '温恒泰')]\n",
      "Ground Truth SPOs:  [['外国民间歌曲选', '作者', '温恒泰']]\n",
      "Text:  平清盛随后在治承四年（1180年）二月迫使高仓天皇退位，拥立自己的孙子，平德子之子即位，是为安德天皇\n",
      "Predicted SPOs:  []\n",
      "Ground Truth SPOs:  [['安德天皇', '父亲', '高仓天皇'], ['安德天皇', '母亲', '平德子'], ['安德天皇', '父亲', '平德子']]\n",
      "Text:  《恋着多喜欢》是梁静茹2005年发行的一首《亲亲》专辑预售单曲，同时也收录在非大陆版的新版《神雕侠侣》原声带中\n",
      "Predicted SPOs:  []\n",
      "Ground Truth SPOs:  [['亲亲', '歌手', '梁静茹'], ['恋着多喜欢', '歌手', '梁静茹']]\n",
      "Text:  今天分享一段很火的bgm，《何以笙箫默》的插曲《好久不见》，视频很短，真的因为只有前奏的谱子呀\n",
      "Predicted SPOs:  []\n",
      "Ground Truth SPOs:  [['何以笙箫默', '主题曲', '好久不见']]\n",
      "Text:  赵允弼（1007—1069），宋太宗赵炅之孙，镇恭懿王赵元偓之子\n",
      "Predicted SPOs:  []\n",
      "Ground Truth SPOs:  [['赵元偓', '朝代', '宋']]\n",
      "Text:  嘉兴中润光学科技有限公司于2012年08月27日在嘉兴市工商局经济开发区分局登记成立\n",
      "Predicted SPOs:  [('嘉兴中润光学科技有限公司', '成立日期', '2012年08月27日')]\n",
      "Ground Truth SPOs:  [['嘉兴中润光学科技有限公司', '成立日期', '2012年08月27日']]\n",
      "Text:  1997年与拍档关咏荷凭借《醉打金枝》在万千星辉颁奖典礼中夺得“最佳惹笑冤家大奖”\n",
      "Predicted SPOs:  []\n",
      "Ground Truth SPOs:  [['醉打金枝', '上映时间', '1997年'], ['醉打金枝', '主演', '关咏荷']]\n",
      "Text:  当然这次旺旺新品营销之所以这么成功，也与产品本身自带热度有关：1)产品拥有知名度旺旺集团起家于1962年成立的宜兰食品，1979年自创品牌“旺旺”(英文名 Want Want)，并打造吉祥物“旺仔\n",
      "Predicted SPOs:  [('旺旺集团', '成立日期', '1962年')]\n",
      "Ground Truth SPOs:  [['旺旺集团', '成立日期', '1962年']]\n",
      "Text:  《我的父亲是板凳》是由中国国际电视总公司出品的电视剧，黄文利和张景坤执导，王宝强、陶虹、张子枫、傅程鹏、午马等主演1\n",
      "Predicted SPOs:  [('我的父亲是板凳', '主演', '傅程鹏'), ('我的父亲是板凳', '主演', '张子枫'), ('我的父亲是板凳', '主演', '午马'), ('我的父亲是板凳', '导演', '张景坤'), ('我的父亲是板凳', '主演', '陶虹'), ('我的父亲是板凳', '导演', '黄文利'), ('我的父亲是板凳', '主演', '王宝强')]\n",
      "Ground Truth SPOs:  [['我的父亲是板凳', '主演', '午马'], ['我的父亲是板凳', '主演', '王宝强'], ['我的父亲是板凳', '主演', '陶虹'], ['我的父亲是板凳', '主演', '傅程鹏'], ['我的父亲是板凳', '导演', '黄文利'], ['我的父亲是板凳', '主演', '张子枫'], ['我的父亲是板凳', '出品公司', '中国国际电视总公司']]\n",
      "Text:  《玻璃爱情》是2006年播出的剧情电视剧，由 宋祖德、王丽娜等主演\n",
      "Predicted SPOs:  [('玻璃爱情', '上映时间', '2006年'), ('玻璃爱情', '主演', '王丽娜'), ('玻璃爱情', '主演', '宋祖德')]\n",
      "Ground Truth SPOs:  [['玻璃爱情', '上映时间', '2006年']]\n",
      "Text:  秘鲁共和国（西班牙语：La República del Perú），简称秘鲁（Peru），是南美洲西部的一个国家，北邻厄瓜多尔和哥伦比亚，东与巴西和玻利维亚接壤，南接智利，西濒太平洋\n",
      "Predicted SPOs:  []\n",
      "Ground Truth SPOs:  [['秘鲁', '官方语言', '西班牙语']]\n"
     ]
    }
   ],
   "source": [
    "to_print = 20\n",
    "for cnt, d in enumerate(dev_data):\n",
    "    if cnt > to_print:\n",
    "        break\n",
    "    print('Text: ', d['text'])\n",
    "    print('Predicted SPOs: ', extract_items(d['text'], s_m, po_m))\n",
    "    print('Ground Truth SPOs: ', d['spo_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544666d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model\n",
    "writer.add_graph(s_m, torch.from_numpy(x).float())\n",
    "writer.add_graph(po_m, torch.fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc8bd2b",
   "metadata": {},
   "source": [
    "# Find the best model saved\n",
    "First iterate trough 0 to 195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0079e47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 62.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: f1: 0.1442, precision: 0.5526, recall: 0.0829, bestf1: 0.1442, bestepoch: 0 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 62.82it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: f1: 0.1995, precision: 0.6325, recall: 0.1184, bestf1: 0.1995, bestepoch: 5 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 65.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: f1: 0.2649, precision: 0.7066, recall: 0.1630, bestf1: 0.2649, bestepoch: 10 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 65.30it/s]\n",
      "6it [00:00, 53.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: f1: 0.3178, precision: 0.7458, recall: 0.2019, bestf1: 0.3178, bestepoch: 15 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 65.18it/s]\n",
      "6it [00:00, 53.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: f1: 0.3289, precision: 0.7396, recall: 0.2115, bestf1: 0.3289, bestepoch: 20 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 62.86it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: f1: 0.3539, precision: 0.7473, recall: 0.2318, bestf1: 0.3539, bestepoch: 25 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 64.50it/s]\n",
      "5it [00:00, 48.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: f1: 0.3743, precision: 0.7355, recall: 0.2510, bestf1: 0.3743, bestepoch: 30 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 64.52it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: f1: 0.3955, precision: 0.7465, recall: 0.2690, bestf1: 0.3955, bestepoch: 35 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 64.67it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: f1: 0.4160, precision: 0.7754, recall: 0.2843, bestf1: 0.4160, bestepoch: 40 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.46it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: f1: 0.4284, precision: 0.7861, recall: 0.2944, bestf1: 0.4284, bestepoch: 45 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 64.17it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: f1: 0.4493, precision: 0.7778, recall: 0.3158, bestf1: 0.4493, bestepoch: 50 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 63.81it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: f1: 0.4614, precision: 0.7956, recall: 0.3249, bestf1: 0.4614, bestepoch: 55 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 63.40it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: f1: 0.4884, precision: 0.8094, recall: 0.3497, bestf1: 0.4884, bestepoch: 60 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 63.79it/s]\n",
      "5it [00:00, 49.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: f1: 0.5078, precision: 0.8201, recall: 0.3677, bestf1: 0.5078, bestepoch: 65 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 63.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: f1: 0.5264, precision: 0.8032, recall: 0.3914, bestf1: 0.5264, bestepoch: 70 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 63.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: f1: 0.5417, precision: 0.8020, recall: 0.4089, bestf1: 0.5417, bestepoch: 75 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 62.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: f1: 0.5337, precision: 0.8045, recall: 0.3993, bestf1: 0.5417, bestepoch: 75 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 63.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: f1: 0.5639, precision: 0.7765, recall: 0.4428, bestf1: 0.5639, bestepoch: 85 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 63.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: f1: 0.5586, precision: 0.8017, recall: 0.4287, bestf1: 0.5639, bestepoch: 85 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 63.43it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: f1: 0.5663, precision: 0.7734, recall: 0.4467, bestf1: 0.5663, bestepoch: 95 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 63.45it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: f1: 0.5567, precision: 0.7919, recall: 0.4292, bestf1: 0.5663, bestepoch: 95 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 63.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105: f1: 0.5590, precision: 0.7806, recall: 0.4354, bestf1: 0.5663, bestepoch: 95 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 59.83it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110: f1: 0.5738, precision: 0.7861, recall: 0.4518, bestf1: 0.5738, bestepoch: 110 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 62.64it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115: f1: 0.5554, precision: 0.7884, recall: 0.4287, bestf1: 0.5738, bestepoch: 110 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120: f1: 0.5620, precision: 0.7798, recall: 0.4394, bestf1: 0.5738, bestepoch: 110 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 62.85it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125: f1: 0.5695, precision: 0.7836, recall: 0.4473, bestf1: 0.5738, bestepoch: 110 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 62.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130: f1: 0.5842, precision: 0.7829, recall: 0.4659, bestf1: 0.5842, bestepoch: 130 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 60.96it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135: f1: 0.5767, precision: 0.7970, recall: 0.4518, bestf1: 0.5842, bestepoch: 130 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:15, 62.70it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140: f1: 0.5844, precision: 0.7837, recall: 0.4659, bestf1: 0.5844, bestepoch: 140 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 60.32it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145: f1: 0.5848, precision: 0.7852, recall: 0.4659, bestf1: 0.5848, bestepoch: 145 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.49it/s]\n",
      "5it [00:00, 46.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150: f1: 0.5922, precision: 0.7657, recall: 0.4828, bestf1: 0.5922, bestepoch: 150 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 60.47it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155: f1: 0.5802, precision: 0.7998, recall: 0.4552, bestf1: 0.5922, bestepoch: 150 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160: f1: 0.5904, precision: 0.7740, recall: 0.4772, bestf1: 0.5922, bestepoch: 150 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 60.32it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165: f1: 0.5750, precision: 0.7805, recall: 0.4552, bestf1: 0.5922, bestepoch: 150 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170: f1: 0.5806, precision: 0.7815, recall: 0.4619, bestf1: 0.5922, bestepoch: 150 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.53it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175: f1: 0.5780, precision: 0.7719, recall: 0.4619, bestf1: 0.5922, bestepoch: 150 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.25it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180: f1: 0.5848, precision: 0.7742, recall: 0.4698, bestf1: 0.5922, bestepoch: 150 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185: f1: 0.5910, precision: 0.7718, recall: 0.4788, bestf1: 0.5922, bestepoch: 150 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 61.34it/s]\n",
      "5it [00:00, 47.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190: f1: 0.5855, precision: 0.7815, recall: 0.4681, bestf1: 0.5922, bestepoch: 150 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195: f1: 0.5795, precision: 0.7974, recall: 0.4552, bestf1: 0.5922, bestepoch: 150 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_epoch = 0\n",
    "best_f1 = 0\n",
    "for e in range(0, 200, 5):\n",
    "    s_m, po_m = load_model('models_real', e, device)\n",
    "    f1, precision, recall = evaluate(s_m, po_m, dev_data)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_epoch = e\n",
    "    print('Epoch %d: f1: %.4f, precision: %.4f, recall: %.4f, bestf1: %.4f, bestepoch: %d \\n ' % (\n",
    "        e, f1, precision, recall, best_f1, best_epoch))\n",
    "    writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0663dfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.30it/s]\n",
      "5it [00:00, 47.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196: f1: 0.5732, precision: 0.7907, recall: 0.4495, bestf1: 0.5922, bestepoch: 150 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.18it/s]\n",
      "5it [00:00, 48.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197: f1: 0.5837, precision: 0.7861, recall: 0.4642, bestf1: 0.5922, bestepoch: 150 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.22it/s]\n",
      "5it [00:00, 47.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198: f1: 0.5924, precision: 0.7824, recall: 0.4766, bestf1: 0.5924, bestepoch: 198 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.13it/s]\n",
      "5it [00:00, 46.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: f1: 0.5868, precision: 0.7738, recall: 0.4726, bestf1: 0.5924, bestepoch: 198 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.11it/s]\n",
      "5it [00:00, 46.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: f1: 0.5899, precision: 0.7738, recall: 0.4766, bestf1: 0.5924, bestepoch: 198 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 61.74it/s]\n",
      "5it [00:00, 46.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201: f1: 0.5974, precision: 0.7788, recall: 0.4845, bestf1: 0.5974, bestepoch: 201 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 61.80it/s]\n",
      "5it [00:00, 46.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202: f1: 0.5943, precision: 0.7757, recall: 0.4817, bestf1: 0.5974, bestepoch: 201 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.49it/s]\n",
      "5it [00:00, 46.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203: f1: 0.5843, precision: 0.7804, recall: 0.4670, bestf1: 0.5974, bestepoch: 201 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.25it/s]\n",
      "5it [00:00, 46.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204: f1: 0.5846, precision: 0.7766, recall: 0.4687, bestf1: 0.5974, bestepoch: 201 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.56it/s]\n",
      "5it [00:00, 47.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205: f1: 0.5941, precision: 0.7793, recall: 0.4800, bestf1: 0.5974, bestepoch: 201 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.25it/s]\n",
      "5it [00:00, 48.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206: f1: 0.5898, precision: 0.7707, recall: 0.4777, bestf1: 0.5974, bestepoch: 201 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 61.95it/s]\n",
      "5it [00:00, 48.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207: f1: 0.5771, precision: 0.7868, recall: 0.4557, bestf1: 0.5974, bestepoch: 201 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.29it/s]\n",
      "5it [00:00, 48.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208: f1: 0.5860, precision: 0.7830, recall: 0.4681, bestf1: 0.5974, bestepoch: 201 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:16, 62.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: f1: 0.5855, precision: 0.7751, recall: 0.4704, bestf1: 0.5974, bestepoch: 201 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for e in range(196, 210):\n",
    "    s_m, po_m = load_model('models_real', e, device)\n",
    "    f1, precision, recall = evaluate(s_m, po_m, dev_data)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_epoch = e\n",
    "    print('Epoch %d: f1: %.4f, precision: %.4f, recall: %.4f, bestf1: %.4f, bestepoch: %d \\n ' % (\n",
    "        e, f1, precision, recall, best_f1, best_epoch))\n",
    "    writer.add_scalar('f1', f1, i)\n",
    "    writer.add_scalar('precision', precision, i)\n",
    "    writer.add_scalar('recall', recall, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecea49e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
