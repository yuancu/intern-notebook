{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "294db828",
   "metadata": {},
   "source": [
    "# Query Mapping - Natural Language Understanding Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b931ad92",
   "metadata": {},
   "source": [
    "## Manually create data for natural language understanding\n",
    "\n",
    "In order to map natural language query to formatted query, we first need to create some labeled data.\n",
    "\n",
    "For validation purpose, I'll only create data for several simple queries with a predefined pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4afa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_path = 'data/dev.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c43e87",
   "metadata": {},
   "source": [
    "Labels are character based! This means a number '431' would be separated into 3 tokens, an English word 'lemon' would become 5 tokens. This is for implementation convinience. Please take this into account when you load texts and tokenize them with other methods.\n",
    "\n",
    "We'll create a small number of data from dev dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae744996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample\n",
    "\n",
    "# number of dialogues to sample our data\n",
    "num_dial = 5000\n",
    "\n",
    "# count total number of dev\n",
    "with open(dev_path) as f:\n",
    "    line_cnt = sum(1 for _ in f)\n",
    "\n",
    "random.seed(42)\n",
    "dial_idxs = sample(range(line_cnt), num_dial)\n",
    "# print(\"sampled dialogue indexes:\", dial_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a44ce59",
   "metadata": {},
   "source": [
    "For dataset generation, I defined some naive patterns for every task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac57b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_predicate_set = set(['毕业院校', '作者', '妻子', '丈夫', '导演', '国籍'])\n",
    "# subject means \"query about subject\"\n",
    "question_templates = {\n",
    "    # {\"object_type\": {\"@value\": \"学校\"}, \"predicate\": \"毕业院校\", \"subject_type\": \"人物\"}\n",
    "    '毕业院校':\n",
    "    {\n",
    "        'ask_subject': [\"有哪些人从{}毕业\", \"{}有哪些知名校友\", \"从{}毕业的名人有哪些\"],\n",
    "        'ask_object': [\"{}毕业于哪里\", \"{}从哪里毕业\", \"{}以前在哪里读书\", \"{}的毕业院校是哪里\", \"{}的毕业院校是什么\"]\n",
    "    },\n",
    "    # {\"object_type\": {\"@value\": \"人物\"}, \"predicate\": \"作者\", \"subject_type\": \"图书作品\"}\n",
    "    '作者':\n",
    "    {\n",
    "        'ask_subject': [\"{}有哪些作品\", \"{}写了什么书\", \"{}写了哪些书\", \"{}有什么著作\"],\n",
    "        'ask_object': [\"{}是谁的作品\", \"{}是谁写的\", \"谁写了{}\", \"{}的作者是谁\"]\n",
    "    },\n",
    "    '妻子':\n",
    "    {\n",
    "        'ask_object': [\"{}的妻子是谁\", \"{}的老婆是谁\", \"{}的配偶是谁\", \"{}和谁结婚了\"]\n",
    "    },\n",
    "    '丈夫':\n",
    "    {\n",
    "        'ask_object': [\"{}的丈夫是谁\", \"{}的老公是谁\", \"{}的配偶是谁\", \"{}和谁结婚了\"]\n",
    "    },\n",
    "    # {\"object_type\": {\"@value\": \"人物\"}, \"predicate\": \"导演\", \"subject_type\": \"影视作品\"}\n",
    "    '导演':\n",
    "    {\n",
    "        'ask_subject': [\"{}有哪些影视作品\", \"{}导演了哪些电影\", \"{}导演了哪些电视剧\"],\n",
    "        'ask_object': [\"{}是谁导演的\", \"{}是谁的作品\", \"{}的导演是谁\"]\n",
    "    },\n",
    "    #{\"object_type\": {\"@value\": \"国家\"}, \"predicate\": \"国籍\", \"subject_type\": \"人物\"}\n",
    "    '国籍':\n",
    "    {\n",
    "        'ask_object': [\"{}来自于哪个国家\", \"{}是哪个国家的人\", \"{}的国籍是什么\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "domain_specific_slot_labels = {\n",
    "    # {\"object_type\": {\"@value\": \"学校\"}, \"predicate\": \"毕业院校\", \"subject_type\": \"人物\"}\n",
    "    '毕业院校': {'subject_label': ['B_name', 'I_name'], 'object_label': ['B_school', 'I_school']},\n",
    "    # {\"object_type\": {\"@value\": \"人物\"}, \"predicate\": \"作者\", \"subject_type\": \"图书作品\"}\n",
    "    '作者': {'subject_label': ['B_book', 'I_book'], 'object_label': ['B_name', 'I_name']},\n",
    "    '妻子': {'subject_label': ['B_name', 'I_name'], 'object_label': ['B_name', 'I_name']},\n",
    "    '丈夫': {'subject_label': ['B_name', 'I_name'], 'object_label': ['B_name', 'I_name']},\n",
    "    # {\"object_type\": {\"@value\": \"人物\"}, \"predicate\": \"导演\", \"subject_type\": \"影视作品\"}\n",
    "    '导演': {'subject_label': ['B_film', 'I_film'], 'object_label': ['B_name', 'I_name']},\n",
    "    #{\"object_type\": {\"@value\": \"国家\"}, \"predicate\": \"国籍\", \"subject_type\": \"人物\"}\n",
    "    '国籍': {'subject_label': ['B_name', 'I_name'], 'object_label': ['B_country', 'I_country']}\n",
    "}\n",
    "\n",
    "domain_specific_intentions = {\n",
    "    '毕业院校':\n",
    "    {\n",
    "        'ask_subject': 'ask_alumni',\n",
    "        'ask_object': 'ask_school'\n",
    "    },\n",
    "    '作者':\n",
    "    {\n",
    "        'ask_subject': 'ask_books',\n",
    "        'ask_object': 'ask_author'\n",
    "    },\n",
    "    '妻子':\n",
    "    {\n",
    "        'ask_object': 'ask_wife'\n",
    "    },\n",
    "    '丈夫':\n",
    "    {\n",
    "        'ask_object': 'ask_husband'\n",
    "    },\n",
    "    '导演':\n",
    "    {\n",
    "        'ask_subject': 'ask_films',\n",
    "        'ask_object': 'ask_director'\n",
    "    },\n",
    "    '国籍':\n",
    "    {\n",
    "        'ask_object': 'ask_nationality'\n",
    "    }\n",
    "}\n",
    "\n",
    "all_slot_labels = ['PAD', 'UNK', 'O', 'B_name', 'I_name'] # name refers to human name\n",
    "all_intentions = ['UNK']\n",
    "for labels in domain_specific_slot_labels.values():\n",
    "    # this keeps orders (compared with using set)\n",
    "    labels = labels['subject_label'] + labels['object_label']\n",
    "    all_slot_labels += [label for label in labels if label not in all_slot_labels]\n",
    "for intentions in domain_specific_intentions.values():\n",
    "    if intentions['ask_object'] not in all_intentions:\n",
    "        all_intentions.append(intentions['ask_object'])\n",
    "    if 'ask_subject' in intentions and intentions['ask_subject'] not in all_intentions:\n",
    "        all_intentions.append(intentions['ask_subject'])\n",
    "print(\"slot labels:\", all_slot_labels)\n",
    "print(\"intentions:\", all_intentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2d4b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import linecache\n",
    "from random import choice, random\n",
    "\n",
    "questions = []\n",
    "question_bios = [] #boundary, inside, outside\n",
    "question_intentions = []\n",
    "\n",
    "for dial_idx in dial_idxs:\n",
    "    line = linecache.getline(dev_path, dial_idx)\n",
    "    spo_list = json.loads(line)['spo_list']\n",
    "    for spo in spo_list:\n",
    "        if spo['predicate'] in used_predicate_set:\n",
    "            question_template = question_templates[spo['predicate']]\n",
    "            # query object with known subject\n",
    "            question_object_template = choice(question_template['ask_object']) # randomly choose a question template\n",
    "            question_object = question_object_template.format(spo['subject'])\n",
    "            # fill bio sequence\n",
    "            question_object_bio = ['O'] * len(question_object)\n",
    "            subject_idx = question_object.find(spo['subject'])\n",
    "            subject_label = domain_specific_slot_labels[spo['predicate']]['subject_label']\n",
    "            question_object_bio[subject_idx] = subject_label[0]\n",
    "            for i in range(subject_idx+1, subject_idx+len(spo['subject'])):\n",
    "                question_object_bio[i] = subject_label[1]\n",
    "            questions.append(question_object)\n",
    "            question_bios.append(question_object_bio)\n",
    "            question_intentions.append(domain_specific_intentions[spo['predicate']]['ask_object'])\n",
    "            # since it is less frequent to query subject, we generate less such query\n",
    "            if random() < 0.5 and 'ask_subject' in question_template:\n",
    "                # query subject with known object\n",
    "                question_subject_template = choice(question_template['ask_subject'])\n",
    "                question_subject = question_subject_template.format(spo['object'])\n",
    "                # fill bio sequence\n",
    "                question_subject_bio = ['O'] * len(question_subject)\n",
    "                object_idx = question_subject.find(spo['object'])\n",
    "                object_label = domain_specific_slot_labels[spo['predicate']]['object_label']\n",
    "                try:\n",
    "                    question_subject_bio[object_idx] = object_label[0]\n",
    "                except:\n",
    "                    print('object_idx', object_idx)\n",
    "                    print('question subject:', question_subject)\n",
    "                    print('question template:', question_template)\n",
    "                    continue\n",
    "                for i in range(object_idx+1, object_idx+len(spo['object'])):\n",
    "                    question_subject_bio[i] = object_label[1]\n",
    "                questions.append(question_subject)\n",
    "                question_bios.append(question_subject_bio)\n",
    "                question_intentions.append(domain_specific_intentions[spo['predicate']]['ask_subject'])\n",
    "print(f\"generated {len(questions)} questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977456c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f083030",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_bios[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad9c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_intentions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b67fd4",
   "metadata": {},
   "source": [
    "### Split train dev and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a98cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fraction = 0.8\n",
    "dev_fraction = 0.1\n",
    "test_fraction = 0.1\n",
    "num_total = len(questions)\n",
    "num_train = int(train_fraction * num_total)\n",
    "num_dev = int(dev_fraction * num_total)\n",
    "num_test = num_total - num_train - num_dev\n",
    "print(f\"Samples for training: {num_train}, for dev: {num_dev}, for test: {num_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f309409",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_questions = questions[:num_train]\n",
    "train_bios = question_bios[:num_train]\n",
    "train_intentions = question_intentions[:num_train]\n",
    "\n",
    "dev_questions = questions[num_train:num_train+num_dev]\n",
    "dev_bios = question_bios[num_train:num_train+num_dev]\n",
    "dev_intentions = question_intentions[num_train:num_train+num_dev]\n",
    "\n",
    "test_questions = questions[num_train+num_dev:]\n",
    "test_bios = question_bios[num_train+num_dev:]\n",
    "test_intentions = question_intentions[num_train+num_dev:]\n",
    "\n",
    "data_dict = {'train': (train_questions, train_bios, train_intentions),\n",
    "            'dev': (dev_questions, dev_bios, dev_intentions),\n",
    "            'test': (test_questions, test_bios, test_intentions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b256ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(train_bios[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f40fb4",
   "metadata": {},
   "source": [
    "Save the data. We name this dataset `naive`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d43e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p data/naive/train\n",
    "mkdir -p data/naive/dev\n",
    "mkdir -p data/naive/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d10a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/naive/intent_label.txt', 'w') as f:\n",
    "    for intention in all_intentions:\n",
    "        f.write(\"%s\\n\" % intention)\n",
    "with open('data/naive/slot_label.txt', 'w') as f:\n",
    "    for slot_label in all_slot_labels:\n",
    "        f.write(\"%s\\n\" % slot_label)\n",
    "for item in ['train', 'dev', 'test']:\n",
    "    with open(f\"data/naive/{item}/seq.in\", 'w') as f:\n",
    "        for question in data_dict[item][0]:\n",
    "            f.write(\"%s\\n\" % question)\n",
    "    with open(f\"data/naive/{item}/seq.out\", 'w') as f:\n",
    "        for bio in data_dict[item][1]:\n",
    "            f.write(\"%s\\n\" % ' '.join(bio))\n",
    "    with open(f\"data/naive/{item}/label\", 'w') as f:\n",
    "        for intent in data_dict[item][2]:\n",
    "            f.write(\"%s\\n\" % intent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d4fe2e",
   "metadata": {},
   "source": [
    "## Train JointBERT Model\n",
    "\n",
    "First you need to install all required python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19842fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8254e761",
   "metadata": {},
   "source": [
    "Then run following script for training. Available options for `--task` is defined in `data_loader.py`. `--model_dir` specifies where to store trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55931c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%% bash\n",
    "\n",
    "python3 main.py --task naive \\\n",
    "                  --model_type bert \\\n",
    "                  --model_dir naive_model \\\n",
    "                  --do_train --do_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ded08cb",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Run script `predict.py` to evaluated trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcc9faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python predict.py --input_file data/naive/test/seq.in --output output/naive_test.out --model_dir naive_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb316e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
