{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08108a1",
   "metadata": {},
   "source": [
    "# Generate Knowlege Graph With Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f6d2a4",
   "metadata": {},
   "source": [
    "## Retrive Triplets\n",
    "Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab1efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b6cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_dir, epoch, device):\n",
    "    s_m = torch.load(os.path.join(model_dir, \"s_{}.pkl\".format(epoch)), map_location=device)\n",
    "    po_m = torch.load(os.path.join(model_dir, \"po_{}.pkl\".format(epoch)), map_location=device)\n",
    "    # reload the model with DataParallel (this will \n",
    "    # be helpful when num of GPUs changes)\n",
    "    s_m = nn.DataParallel(s_m.module)\n",
    "    po_m = nn.DataParallel(po_m.module)\n",
    "    return s_m, po_m\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a11cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_epoch = 210\n",
    "model_dir = 'models_real'\n",
    "s_m, po_m = load_model(model_dir, model_epoch, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e103f2",
   "metadata": {},
   "source": [
    "Extract triplets from dev data (currently )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8573cacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a bad sequential implementation\n",
    "def extract_items(text_in, s_m, po_m):\n",
    "    R = []\n",
    "    _s = [char2id.get(c, 1) for c in text_in]\n",
    "    _s = np.array([_s])\n",
    "    _k1, _k2, t, t_max, mask = s_m(torch.LongTensor(_s).to(device))\n",
    "    _k1, _k2 = _k1[0, :, 0], _k2[0, :, 0]\n",
    "    _kk1s = []\n",
    "    for i, _kk1 in enumerate(_k1):\n",
    "        if _kk1 > 0.5:\n",
    "            _subject = ''\n",
    "            for j, _kk2 in enumerate(_k2[i:]):\n",
    "                if _kk2 > 0.5:\n",
    "                    _subject = text_in[i: i+j+1]\n",
    "                    break\n",
    "            if _subject:\n",
    "                _k1, _k2 = torch.LongTensor([[i]]), torch.LongTensor(\n",
    "                    [[i+j]])  # np.array([i]), np.array([i+j])\n",
    "                _o1, _o2 = po_m(t.to(device), t_max.to(\n",
    "                    device), _k1.to(device), _k2.to(device))\n",
    "                _o1, _o2 = _o1.cpu().data.numpy(), _o2.cpu().data.numpy()\n",
    "\n",
    "                _o1, _o2 = np.argmax(_o1[0], 1), np.argmax(_o2[0], 1)\n",
    "\n",
    "                for i, _oo1 in enumerate(_o1):\n",
    "                    if _oo1 > 0:\n",
    "                        for j, _oo2 in enumerate(_o2[i:]):\n",
    "                            if _oo2 == _oo1:\n",
    "                                _object = text_in[i: i+j+1]\n",
    "                                _predicate = id2predicate[_oo1]\n",
    "                                # print((_subject, _predicate, _object))\n",
    "                                R.append((_subject, _predicate, _object))\n",
    "                                break\n",
    "        _kk1s.append(_kk1.data.cpu().numpy())\n",
    "    _kk1s = np.array(_kk1s)\n",
    "    return list(set(R))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8a044",
   "metadata": {},
   "source": [
    "Load dev data, and corresponding schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee10f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_path = 'generated/dev_data_me.json'\n",
    "dev_data = json.load(open(dev_path))\n",
    "generated_char_path = 'generated/all_chars_me.json'\n",
    "id2char, char2id = json.load(open(generated_char_path))\n",
    "generated_schema_path =  'generated/schemas_me.json'\n",
    "id2predicate, predicate2id = json.load(open(generated_schema_path))\n",
    "id2predicate = {int(i): j for i, j in id2predicate.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68718c5a",
   "metadata": {},
   "source": [
    "Write to `pandas` frame first, then write to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f150fdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ad972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'subject':[], 'predicate':[], 'object':[]})\n",
    "for d in tqdm(iter(dev_data)):\n",
    "    items = extract_items(d['text'], s_m, po_m)\n",
    "    for item in items:\n",
    "        df.loc[len(df)] = item\n",
    "\n",
    "print(\"num of extracted relations from dev set is:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d964017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('generated/triplets.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f358103",
   "metadata": {},
   "source": [
    "Create knowledge graph with saved triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600374a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the length of existing predicates\n",
    "len(set(df['predicate']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dcec83",
   "metadata": {},
   "source": [
    "### Create relation dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d1b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_dict = {}\n",
    "schema_path = 'data/schema.json'\n",
    "with open(schema_path) as f:\n",
    "    for l in tqdm(f):\n",
    "        rel = json.loads(l)\n",
    "        #schemas.add(a['predicate'])\n",
    "        predicate = rel['predicate']\n",
    "        sub_type = rel['subject_type']\n",
    "        obj_type = rel['object_type']['@value']\n",
    "        rel_dict[predicate] = {'subject_type': sub_type, 'object_type': obj_type}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1167ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d680f02",
   "metadata": {},
   "source": [
    "ID is currently constructed in a very simple way:\n",
    "```python\n",
    "node_id = 'node_' + node_type + '_' + node_name\n",
    "edge_id = 'edge_' + predicate + '_' + from + '_' + to\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffcc883",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_df = pd.DataFrame({'~id':[], '~label':[], 'name': []})\n",
    "edge_df = pd.DataFrame({'~id':[], '~from':[], '~to':[], '~label':[]})\n",
    "\n",
    "node_dict = {}\n",
    "\n",
    "# currently id is constructed naively.\n",
    "def node_name2id(entity_type, entity_name):\n",
    "    return 'node_' + entity_type + '_' + entity_name\n",
    "\n",
    "for idx, row in rel_df.iterrows():\n",
    "    sub = row['subject']\n",
    "    obj = row['object']\n",
    "    rel = row['predicate']\n",
    "    sub_type = rel_dict[rel]['subject_type']\n",
    "    obj_type = rel_dict[rel]['object_type']\n",
    "    sub_id = 'node_' + sub_type + '_' + sub\n",
    "    obj_id = 'node_' + obj_type + '_' + obj\n",
    "    # order matter: ~id, ~label, name\n",
    "    node_dict[sub_id] = [sub_type, sub]\n",
    "    node_dict[obj_id] = [obj_type, obj]\n",
    "    edge_id = 'edge_' + rel + '_' + sub_id + '_' + obj_id\n",
    "    edge_df.loc[len(edge_df)] = [edge_id, sub_id, obj_id, rel]\n",
    "    \n",
    "for key, val in node_dict.items():\n",
    "    node_df.loc[len(node_df)] = [key, val[0], val[1]]  \n",
    "\n",
    "print(\"We have scanned {} nodes and {} relations\".format(len(node_df), len(edge_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5110258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da87e363",
   "metadata": {},
   "source": [
    "Save nodes and relations to csv file and upload it to Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_df.to_csv('generated/nodes.csv', index=False)\n",
    "edge_df.to_csv('generated/edges.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fcd820",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "export S3_SAVE_BUCKET=\"sm-nlp-data\"\n",
    "export SAVE_PATH=\"ie-baseline/outputs\"\n",
    "aws s3 cp ./generated/edges.csv s3://$S3_SAVE_BUCKET/$SAVE_PATH/edges.csv\n",
    "aws s3 cp ./generated/nodes.csv s3://$S3_SAVE_BUCKET/$SAVE_PATH/nodes.csv\n",
    "\n",
    "echo \"The path for the Property Graph bulk loading step is 's3://$S3_SAVE_BUCKET/$SAVE_PATH/'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed0301d",
   "metadata": {},
   "source": [
    "## Load Graph Data into Neptune\n",
    "- Neptune endpoint & port: database-1-instance-1.c2ycbhkszo5s.us-east-1.neptune.amazonaws.com:8182 [info](https://console.aws.amazon.com/neptune/home?region=us-east-1#database:id=database-1-instance-1;is-cluster=false;tab=connectivity)\n",
    "- Source:\n",
    "    - s3://sm-nlp-data/ie-baseline/outputs/nodes.csv\n",
    "    - s3://sm-nlp-data/ie-baseline/outputs/edges.csv\n",
    "- IAM role ARN: arn:aws:iam::093729152554:role/service-role/AWSNeptuneNotebookRole-NepTestRole [link](https://console.aws.amazon.com/iam/home?region=us-east-1#/roles/AWSNeptuneNotebookRole-NepTestRole)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049991b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "    -H 'Content-Type: application/json' \\\n",
    "    https://database-1-instance-1.c2ycbhkszo5s.us-east-1.neptune.amazonaws.com:8182/loader -d '\n",
    "    {\n",
    "      \"source\" : \"s3://sm-nlp-data/ie-baseline/outputs/\",\n",
    "      \"format\" : \"csv\",\n",
    "      \"iamRoleArn\" : \"arn:aws:iam::093729152554:role/aws-service-role/rds.amazonaws.com/AWSServiceRoleForRDS\",\n",
    "      \"region\" : \"us-east-1\",\n",
    "      \"failOnError\" : \"FALSE\",\n",
    "      \"parallelism\" : \"MEDIUM\",\n",
    "      \"updateSingleCardinalityProperties\" : \"FALSE\",\n",
    "      \"queueRequest\" : \"TRUE\",\n",
    "      \"dependencies\" : []\n",
    "    }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f01f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws configure list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d2b882",
   "metadata": {},
   "outputs": [],
   "source": [
    "%status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%gremlin\n",
    "g.V()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45b582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%graph_notebook_config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
