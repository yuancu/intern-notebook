{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc2d42bb",
   "metadata": {},
   "source": [
    "# Generate Knowlege Graph With Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5348e6d4",
   "metadata": {},
   "source": [
    "## Retrive Triplets\n",
    "Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ead64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ef3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe0ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e0206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_dir, epoch, device):\n",
    "    s_m = torch.load(os.path.join(model_dir, \"s_{}.pkl\".format(epoch)), map_location=device)\n",
    "    po_m = torch.load(os.path.join(model_dir, \"po_{}.pkl\".format(epoch)), map_location=device)\n",
    "    # reload the model with DataParallel (this will \n",
    "    # be helpful when num of GPUs changes)\n",
    "    s_m = nn.DataParallel(s_m.module)\n",
    "    po_m = nn.DataParallel(po_m.module)\n",
    "    return s_m, po_m\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_epoch = 210\n",
    "model_dir = 'models_real'\n",
    "s_m, po_m = load_model(model_dir, model_epoch, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c896922b",
   "metadata": {},
   "source": [
    "Extract triplets from dev data (currently )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920100ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a bad sequential implementation\n",
    "def extract_items(text_in, s_m, po_m):\n",
    "    R = []\n",
    "    _s = [char2id.get(c, 1) for c in text_in]\n",
    "    _s = np.array([_s])\n",
    "    _k1, _k2, t, t_max, mask = s_m(torch.LongTensor(_s).to(device))\n",
    "    _k1, _k2 = _k1[0, :, 0], _k2[0, :, 0]\n",
    "    _kk1s = []\n",
    "    for i, _kk1 in enumerate(_k1):\n",
    "        if _kk1 > 0.5:\n",
    "            _subject = ''\n",
    "            for j, _kk2 in enumerate(_k2[i:]):\n",
    "                if _kk2 > 0.5:\n",
    "                    _subject = text_in[i: i+j+1]\n",
    "                    break\n",
    "            if _subject:\n",
    "                _k1, _k2 = torch.LongTensor([[i]]), torch.LongTensor(\n",
    "                    [[i+j]])  # np.array([i]), np.array([i+j])\n",
    "                _o1, _o2 = po_m(t.to(device), t_max.to(\n",
    "                    device), _k1.to(device), _k2.to(device))\n",
    "                _o1, _o2 = _o1.cpu().data.numpy(), _o2.cpu().data.numpy()\n",
    "\n",
    "                _o1, _o2 = np.argmax(_o1[0], 1), np.argmax(_o2[0], 1)\n",
    "\n",
    "                for i, _oo1 in enumerate(_o1):\n",
    "                    if _oo1 > 0:\n",
    "                        for j, _oo2 in enumerate(_o2[i:]):\n",
    "                            if _oo2 == _oo1:\n",
    "                                _object = text_in[i: i+j+1]\n",
    "                                _predicate = id2predicate[_oo1]\n",
    "                                # print((_subject, _predicate, _object))\n",
    "                                R.append((_subject, _predicate, _object))\n",
    "                                break\n",
    "        _kk1s.append(_kk1.data.cpu().numpy())\n",
    "    _kk1s = np.array(_kk1s)\n",
    "    return list(set(R))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p36",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
