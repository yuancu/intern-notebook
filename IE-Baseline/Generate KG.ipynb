{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d369a232",
   "metadata": {},
   "source": [
    "# Generate Knowlege Graph With Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e318446",
   "metadata": {},
   "source": [
    "## Retrive Triplets\n",
    "Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7808f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a86d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d847cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_dir, epoch, device):\n",
    "    s_m = torch.load(os.path.join(model_dir, \"s_{}.pkl\".format(epoch)), map_location=device)\n",
    "    po_m = torch.load(os.path.join(model_dir, \"po_{}.pkl\".format(epoch)), map_location=device)\n",
    "    # reload the model with DataParallel (this will \n",
    "    # be helpful when num of GPUs changes)\n",
    "    s_m = nn.DataParallel(s_m.module)\n",
    "    po_m = nn.DataParallel(po_m.module)\n",
    "    return s_m, po_m\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bccaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_epoch = 210\n",
    "model_dir = 'models_real'\n",
    "s_m, po_m = load_model(model_dir, model_epoch, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8681ea44",
   "metadata": {},
   "source": [
    "Extract triplets from dev data (currently )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e95ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a bad sequential implementation\n",
    "def extract_items(text_in, s_m, po_m):\n",
    "    R = []\n",
    "    _s = [char2id.get(c, 1) for c in text_in]\n",
    "    _s = np.array([_s])\n",
    "    _k1, _k2, t, t_max, mask = s_m(torch.LongTensor(_s).to(device))\n",
    "    _k1, _k2 = _k1[0, :, 0], _k2[0, :, 0]\n",
    "    _kk1s = []\n",
    "    for i, _kk1 in enumerate(_k1):\n",
    "        if _kk1 > 0.5:\n",
    "            _subject = ''\n",
    "            for j, _kk2 in enumerate(_k2[i:]):\n",
    "                if _kk2 > 0.5:\n",
    "                    _subject = text_in[i: i+j+1]\n",
    "                    break\n",
    "            if _subject:\n",
    "                _k1, _k2 = torch.LongTensor([[i]]), torch.LongTensor(\n",
    "                    [[i+j]])  # np.array([i]), np.array([i+j])\n",
    "                _o1, _o2 = po_m(t.to(device), t_max.to(\n",
    "                    device), _k1.to(device), _k2.to(device))\n",
    "                _o1, _o2 = _o1.cpu().data.numpy(), _o2.cpu().data.numpy()\n",
    "\n",
    "                _o1, _o2 = np.argmax(_o1[0], 1), np.argmax(_o2[0], 1)\n",
    "\n",
    "                for i, _oo1 in enumerate(_o1):\n",
    "                    if _oo1 > 0:\n",
    "                        for j, _oo2 in enumerate(_o2[i:]):\n",
    "                            if _oo2 == _oo1:\n",
    "                                _object = text_in[i: i+j+1]\n",
    "                                _predicate = id2predicate[_oo1]\n",
    "                                # print((_subject, _predicate, _object))\n",
    "                                R.append((_subject, _predicate, _object))\n",
    "                                break\n",
    "        _kk1s.append(_kk1.data.cpu().numpy())\n",
    "    _kk1s = np.array(_kk1s)\n",
    "    return list(set(R))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fea1070",
   "metadata": {},
   "source": [
    "Load dev data, and corresponding schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19fd19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_path = 'generated/dev_data_me.json'\n",
    "dev_data = json.load(open(dev_path))\n",
    "generated_char_path = 'generated/all_chars_me.json'\n",
    "id2char, char2id = json.load(open(generated_char_path))\n",
    "generated_schema_path =  'generated/schemas_me.json'\n",
    "id2predicate, predicate2id = json.load(open(generated_schema_path))\n",
    "id2predicate = {int(i): j for i, j in id2predicate.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae523f",
   "metadata": {},
   "source": [
    "Write to `pandas` frame first, then write to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236f972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb948f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'subject':[], 'predicate':[], 'object':[]})\n",
    "for d in tqdm(iter(dev_data)):\n",
    "    items = extract_items(d['text'], s_m, po_m)\n",
    "    for item in items:\n",
    "        df.loc[len(df)] = item\n",
    "\n",
    "print(\"num of extracted relations from dev set is:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a4198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('generated/triplets.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3f4cca",
   "metadata": {},
   "source": [
    "Create knowledge graph with saved triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c3da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the length of existing predicates\n",
    "len(set(df['predicate']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f732cec0",
   "metadata": {},
   "source": [
    "### Create relation dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bdfe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_dict = {}\n",
    "schema_path = 'data/schema.json'\n",
    "with open(schema_path) as f:\n",
    "    for l in tqdm(f):\n",
    "        rel = json.loads(l)\n",
    "        #schemas.add(a['predicate'])\n",
    "        predicate = rel['predicate']\n",
    "        sub_type = rel['subject_type']\n",
    "        obj_type = rel['object_type']['@value']\n",
    "        rel_dict[predicate] = {'subject_type': sub_type, 'object_type': obj_type}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce509046",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5822b0f",
   "metadata": {},
   "source": [
    "ID is currently constructed in a very simple way:\n",
    "```python\n",
    "node_id = 'node_' + node_type + '_' + node_name\n",
    "edge_id = 'edge_' + predicate + '_' + from + '_' + to\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a9c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_df = pd.DataFrame({'~id':[], '~label':[], 'name': []})\n",
    "edge_df = pd.DataFrame({'~id':[], '~from':[], '~to':[], '~label':[]})\n",
    "\n",
    "node_dict = {}\n",
    "\n",
    "# currently id is constructed naively.\n",
    "def node_name2id(entity_type, entity_name):\n",
    "    return 'node_' + entity_type + '_' + entity_name\n",
    "\n",
    "for idx, row in rel_df.iterrows():\n",
    "    sub = row['subject']\n",
    "    obj = row['object']\n",
    "    rel = row['predicate']\n",
    "    sub_type = rel_dict[rel]['subject_type']\n",
    "    obj_type = rel_dict[rel]['object_type']\n",
    "    sub_id = 'node_' + sub_type + '_' + sub\n",
    "    obj_id = 'node_' + obj_type + '_' + obj\n",
    "    # order matter: ~id, ~label, name\n",
    "    node_dict[sub_id] = [sub_type, sub]\n",
    "    node_dict[obj_id] = [obj_type, obj]\n",
    "    edge_id = 'edge_' + rel + '_' + sub_id + '_' + obj_id\n",
    "    edge_df.loc[len(edge_df)] = [edge_id, sub_id, obj_id, rel]\n",
    "    \n",
    "for key, val in node_dict.items():\n",
    "    node_df.loc[len(node_df)] = [key, val[0], val[1]]  \n",
    "\n",
    "print(\"We have scanned {} nodes and {} relations\".format(len(node_df), len(edge_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326db2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "794efef8",
   "metadata": {},
   "source": [
    "Save nodes and relations to csv file and upload it to Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be47b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_df.to_csv('generated/nodes.csv', index=False)\n",
    "edge_df.to_csv('generated/edges.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127be54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "export S3_SAVE_BUCKET=\"sm-nlp-data\"\n",
    "export SAVE_PATH=\"ie-baseline/outputs\"\n",
    "aws s3 cp ./generated/edges.csv s3://$S3_SAVE_BUCKET/$SAVE_PATH/edges.csv\n",
    "aws s3 cp ./generated/nodes.csv s3://$S3_SAVE_BUCKET/$SAVE_PATH/nodes.csv\n",
    "\n",
    "echo \"The path for the Property Graph bulk loading step is 's3://$S3_SAVE_BUCKET/$SAVE_PATH/'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def322e",
   "metadata": {},
   "source": [
    "## Load Graph Data into Neptune\n",
    "- Neptune endpoint & port: database-1-instance-1.c2ycbhkszo5s.us-east-1.neptune.amazonaws.com:8182 [info](https://console.aws.amazon.com/neptune/home?region=us-east-1#database:id=database-1-instance-1;is-cluster=false;tab=connectivity)\n",
    "- Source:\n",
    "    - s3://sm-nlp-data/ie-baseline/outputs/nodes.csv\n",
    "    - s3://sm-nlp-data/ie-baseline/outputs/edges.csv\n",
    "- IAM role ARN: arn:aws:iam::093729152554:role/service-role/AWSNeptuneNotebookRole-NepTestRole [link](https://console.aws.amazon.com/iam/home?region=us-east-1#/roles/AWSNeptuneNotebookRole-NepTestRole)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5759698e",
   "metadata": {},
   "source": [
    "*Trouble shooting*:\n",
    "\n",
    "- You have to create an endpoint following the section 'Creating an Amazon S3 VPC Endpoint' in this [post](https://docs.aws.amazon.com/neptune/latest/userguide/bulk-load-data.html).\n",
    "- Choose the endpoint type as 'Gateway'.\n",
    "- Do select the check box next to the route tables that are associated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf14a3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"status\" : \"200 OK\",\n",
      "    \"payload\" : {\n",
      "        \"loadId\" : \"ee8874f8-5e29-44c2-8934-33d41d0d1bee\"\n",
      "    }\n",
      "}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   480  100   110  100   370    774   2605 --:--:-- --:--:-- --:--:--  3380\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "    -H 'Content-Type: application/json' \\\n",
    "    https://database-2-instance-1.c2ycbhkszo5s.us-east-1.neptune.amazonaws.com:8182/loader -d '\n",
    "    {\n",
    "      \"source\" : \"s3://sm-nlp-data/ie-baseline/outputs/\",\n",
    "      \"format\" : \"csv\",\n",
    "      \"iamRoleArn\" : \"arn:aws:iam::093729152554:role/NeptuneLoadFromS3\",\n",
    "      \"region\" : \"us-east-1\",\n",
    "      \"failOnError\" : \"FALSE\",\n",
    "      \"parallelism\" : \"MEDIUM\",\n",
    "      \"updateSingleCardinalityProperties\" : \"FALSE\",\n",
    "      \"queueRequest\" : \"TRUE\",\n",
    "      \"dependencies\" : []\n",
    "    }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b3a83",
   "metadata": {},
   "source": [
    "Query database through cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "525c2388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"requestId\":\"805a3c0d-733c-4b63-8dc5-1cf3626d729f\",\"status\":{\"message\":\"\",\"code\":200,\"attributes\":{\"@type\":\"g:Map\",\"@value\":[]}},\"result\":{\"data\":{\"@type\":\"g:List\",\"@value\":[{\"@type\":\"g:Vertex\",\"@value\":{\"id\":\"node_机构_步步惊心\",\"label\":\"机构\",\"properties\":{\"name\":[{\"@type\":\"g:VertexProperty\",\"@value\":{\"id\":{\"@type\":\"g:Int32\",\"@value\":-1396949598},\"value\":\"步步惊心\",\"label\":\"name\"}}]}}},{\"@type\":\"g:Vertex\",\"@value\":{\"id\":\"node_Text_何以笙箫默》改编自顾漫同名小说《花千骨\",\"label\":\"Text\",\"properties\":{\"name\":[{\"@type\":\"g:VertexProperty\",\"@value\":{\"id\":{\"@type\":\"g:Int32\",\"@value\":-1258493771},\"value\":\"何以笙箫默》改编自顾漫同名小说《花千骨\",\"label\":\"name\"}}]}}},{\"@type\":\"g:Vertex\",\"@value\":{\"id\":\"node_国家_步步惊心\",\"label\":\"国家\",\"properties\":{\"name\":[{\"@type\":\"g:VertexProperty\",\"@value\":{\"id\":{\"@type\":\"g:Int32\",\"@value\":-1990792653},\"value\":\"步步惊心\",\"label\":\"name\"}}]}}},{\"@type\":\"g:Vertex\",\"@value\":{\"id\":\"node_语言_顾漫\",\"label\":\"语言\",\"properties\":{\"name\":[{\"@type\":\"g:VertexProperty\",\"@value\":{\"id\":{\"@type\":\"g:Int32\",\"@value\":206157145},\"value\":\"顾漫\",\"label\":\"name\"}}]}}},{\"@type\":\"g:Vertex\",\"@value\":{\"id\":\"node_Text_甄嬛传\",\"label\":\"Text\",\"properties\":{\"name\":[{\"@type\":\"g:VertexProperty\",\"@value\":{\"id\":{\"@type\":\"g:Int32\",\"@value\":598115573},\"value\":\"甄嬛传\",\"label\":\"name\"}}]}}}]},\"meta\":{\"@type\":\"g:Map\",\"@value\":[]}}}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1448  100  1420  100    28  54615   1076 --:--:-- --:--:-- --:--:-- 55692\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST -d '{\"gremlin\":\"g.V().limit(5)\"}' https://database-2-instance-1.c2ycbhkszo5s.us-east-1.neptune.amazonaws.com:8182/gremlin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9b1cc8",
   "metadata": {},
   "source": [
    "We set up a load balancer to redirect traffics from outside the VPC to the neptune endpoints.\n",
    "\n",
    "After configuring an ALB(application load balancer), the following command can be executed on your local computer (currently anywhere).\n",
    "\n",
    "Architectures and best practices of load balancers are detailed [here](https://github.com/aws-samples/aws-dbs-refarch-graph/tree/master/src/connecting-using-a-load-balancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2bd8f112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"requestId\":\"ee0d092c-4f50-4fdd-a50a-260a21be4cb6\",\"status\":{\"message\":\"\",\"code\":200,\"attributes\":{\"@type\":\"g:Map\",\"@value\":[]}},\"result\":{\"data\":{\"@type\":\"g:List\",\"@value\":[{\"@type\":\"g:Edge\",\"@value\":{\"id\":\"edge_导演_node_影视作品_科库雷克_node_人物_捷克\",\"label\":\"导演\",\"inVLabel\":\"人物\",\"outVLabel\":\"影视作品\",\"inV\":\"node_人物_捷克\",\"outV\":\"node_影视作品_科库雷克\"}},{\"@type\":\"g:Edge\",\"@value\":{\"id\":\"edge_获奖_node_娱乐人物_末日迷踪_node_奖项_尼古拉斯·凯奇\",\"label\":\"获奖\",\"inVLabel\":\"奖项\",\"outVLabel\":\"娱乐人物\",\"inV\":\"node_奖项_尼古拉斯·凯奇\",\"outV\":\"node_娱乐人物_末日迷踪\"}}]},\"meta\":{\"@type\":\"g:Map\",\"@value\":[]}}}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   731  100   703  100    28  27038   1076 --:--:-- --:--:-- --:--:-- 28115\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST -d '{\"gremlin\":\"g.E().limit(2)\"}' alb-neptune-test-62758122.us-east-1.elb.amazonaws.com/gremlin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53005019",
   "metadata": {},
   "source": [
    "## Miscellaneous (debugging etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11c47034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name                    Value             Type    Location\n",
      "      ----                    -----             ----    --------\n",
      "   profile                <not set>             None    None\n",
      "access_key     ****************MSGJ shared-credentials-file    \n",
      "secret_key     ****************P92x shared-credentials-file    \n",
      "    region                us-east-1      config-file    ~/.aws/config\n"
     ]
    }
   ],
   "source": [
    "!aws configure list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "561987de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'healthy',\n",
       " 'startTime': 'Thu Jun 17 08:46:17 UTC 2021',\n",
       " 'dbEngineVersion': '1.0.4.2.R2',\n",
       " 'role': 'writer',\n",
       " 'gremlin': {'version': 'tinkerpop-3.4.10'},\n",
       " 'sparql': {'version': 'sparql-1.1'},\n",
       " 'labMode': {'NeptuneML': 'disabled',\n",
       "  'ObjectIndex': 'disabled',\n",
       "  'DFEQueryEngine': 'disabled',\n",
       "  'ReadWriteConflictDetection': 'enabled'},\n",
       " 'resultCache': {'status': 'Disabled'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5565b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3391fcdfaea54f67b8010ffd14c67a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(layout=Layout(max_height='600px', overflow='scroll', width='100%')), Output(layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%gremlin\n",
    "g.V().out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1124a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"host\": \"database-2.cluster-c2ycbhkszo5s.us-east-1.neptune.amazonaws.com\",\n",
      "  \"port\": 8182,\n",
      "  \"auth_mode\": \"DEFAULT\",\n",
      "  \"load_from_s3_arn\": \"\",\n",
      "  \"ssl\": true,\n",
      "  \"aws_region\": \"us-east-1\",\n",
      "  \"sparql\": {\n",
      "    \"path\": \"sparql\"\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graph_notebook.configuration.generate_config.Configuration at 0x7f57a0913898>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%graph_notebook_config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
